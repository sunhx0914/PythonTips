就业班

### 0 网络编程

所谓的网络编程就是，让在不同的电脑上的软件能够进行数据传递，即进程之间的通信

##### ip地址

ip地址：用来在网络中标记一台电脑，比如192.168.1.1；在本地局域网上是唯一的。

##### 端口

**端口是通过端口号来标记**的，端口号只有整数，范围是从**0到65535** 

端口号不是随意使用的，而是按照一定的规定进行分配。这里不做详细讲解，只介绍一下知名端口和动态端口。

**知名端口**是众所周知的端口号，**范围从0到1023**，80端口分配给HTTP服务，21端口分配给FTP服务

**动态端口**的范围是从**1024到65535**，动态分配是指当一个系统程序或应用程序程序需要网络通信时，它向主机申请一个端口，主机**从可用的端口号中分配一个**供它使用。当这个程序**关闭时**，同时也就**释放**了所占用的端口号

> 端口有什么用呢 ？ 我们知道，一台拥有IP地址的主机可以提供许多服务，比如HTTP（万维网服务）、FTP（文件传输）、SMTP（电子邮件）等，这些服务完全可以通过1个IP地址来实现。那么，主机是怎样区分不同的网络服务呢？显然不能只靠IP地址，因为IP地址与网络服务的关系是一对多的关系。实际上是**通过“IP地址+端口号”来区分不同的服务的**。 需要注意的是，**端口并不是一一对应的**。比如你的电脑作为客户机访问一台WWW服务器时，WWW服务器使用“80”端口与你的电脑通信，但你的电脑则可能使用“3457”这样的端口。 
>
> **ip用于区分主机，端口用于区分服务**

#### Socket

不同电脑上的进程之间如何通信：首要解决的问题是如何唯一标识一个进程。

TCP/IP协议族解决了这个问题，网络层的 **ip地址** 可以唯一标识网络中的主机，而传输层的 **协议+端口** 可以唯一标识主机中的应用进程（进程）。( 由于TCP/IP传输层的两个协议TCP和UDP是完全独立的两个软件模块，因此各自的端口号也相互独立，如TCP有一个255号端口，UDP也可以有一个255号端口，二者并不冲突。 )

socket(简称 `套接字`) 是进程间通信的一种方式，它与其他进程间通信的一个主要不同是：它能实现不同主机间的进程间通信，我们网络上各种各样的服务大多都是基于 Socket 来完成通信的。

##### 创建socket

在 Python 中  使用 socket 模块的 socket 函数来创建一个 socket 对象：

```python
import socket
socket.socket(AddressFamily, Type)
```

函数 socket.socket 创建一个 socket，该函数带有两个参数：

- Address Family：可以选择 AF_INET（用于 Internet 进程间通信） 或者 AF_UNIX（用于同一台机器进程间通信）,实际工作中常用AF_INET
- Type：套接字类型，可以是 SOCK_STREAM（流式套接字，主要用于 TCP 协议）或者 SOCK_DGRAM（数据报套接字，主要用于 UDP 协议）

##### 创建一个tcp socket（tcp套接字）

```python
import socket
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)  # 创建tcp的套接字
# ...这里是使用套接字的功能（省略）...
s.close()  # 不用的时候，关闭套接字
```

##### 创建一个udp socket（udp套接字）

```python
import socket
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)  # 创建udp的套接字
# ...这里是使用套接字的功能（省略）...
s.close()  # 不用的时候，关闭套接字
```

套接字使用流程 与 文件的使用流程很类似：创建套接字 --> 使用套接字收/发数据 --> 关闭套接字

#### UDP

<img src="https://user-images.githubusercontent.com/51505633/79089472-dc12f980-7d78-11ea-8f35-4bdf053ac735.jpg" alt="udp_new" style="zoom: 80%;" />

用户数据报协议（UDP，User Datagram Protocol）。UDP 为应用程序提供了一种无需建立连接就可以发送数据的方法。 

##### udp网络程序-发送数据

```python
from socket import *
# 1. 创建udp套接字
udp_socket = socket(AF_INET, SOCK_DGRAM)
# 2. 准备接收方的地址
# '192.168.1.103'表示目的ip地址   8080表示目的端口
dest_addr = ('192.168.1.103', 8080)  # 注意 是元组，ip是字符串，端口是数字
# 3. 从键盘获取数据
send_data = input("请输入要发送的数据:")
# 4. 发送数据到指定的电脑上的指定程序中
udp_socket.sendto(send_data.encode('utf-8'), dest_addr)  
# 数据需要为字节 字符串时可直接 b"..."
# 5. 关闭套接字
udp_socket.close()
```

一般情况下，在一台电脑上运行的网络程序有很多，为了不与其他的网络程序占用同一个端口号，往往在编程中， **udp的端口号一般不绑定** 。但是如果需要做成一个**服务器端的程序** 的话，是需要**绑定**的。

发送数据流程：创建套接字 —— 发送数据 ——关闭

接收数据流程：创建套接字 —— 绑定本地信息 —— 接收数据 ——关闭

##### udp网络程序-发送、接收数据

```python
from socket import *
udp_socket = socket(AF_INET, SOCK_DGRAM)
# 2. 绑定本地的相关信息，如果一个网络程序不绑定，则系统会随机分配
local_addr = ('', 7788)  # ip地址和端口号，ip一般不用写，表示本机的任何一个ip
udp_socket.bind(local_addr)  # 必须绑定自己电脑的 ip 和 port
dest_addr = ('192.168.0.105', 4567)
send_data = input("请输入要发送的数据:")
udp_socket.sendto(send_data.encode('utf-8'), dest_addr)  # 编码
# 6. 等待接收对方发送的数据
recv_data = udp_socket.recvfrom(1024)  # 1024表示本次接收的最大字节数
# 6. 显示对方发送的数据
print(recv_data)
# 接收到的数据recv_data是一个元组(接收到的数据，(发送方的ip, port))
# 第1个元素是对方发送的数据，第2个元素是对方的ip和端口
recv_msg = recv_data[0]  # 存储接收的数据
send_addr = recv_data[1]  # 存储发送方的地址信息
print("%s:%s" % (str(send_addr), recv_msg.decode("gbk")))  # 解码 window 默认 GBK
udp_socket.close()
```

自己电脑多个端口试验时，ip 可设为 127.0.0.1

recvfrom() 在没有收到数据时堵塞

没调用recvfrom() 时收到的数据，由操作系统暂存，调用时再读

套接字可同时收发 —— 全双工       (单工、半双工、全双工)

##### python3编码转换

`str->bytes:encode编码 ; bytes->str:decode解码`

**字符串通过编码成为字节码，字节码通过解码成为字符串。**

其中decode()与encode()方法可以接受参数，其声明分别为:

```python
bytes.decode(encoding="utf-8", errors="strict")
str.encode(encoding="utf-8", errors="strict")
```

其中的encoding是指在解码编码过程中使用的编码(此处指“编码方案”是名词)，errors是指错误的处理方案。

#### TCP

**TCP协议，传输控制协议（Transmission Control Protocol，TCP）**是一种面向连接的、可靠的、基于字节流的传输层通信协议。

TCP通信需要经过**创建连接、数据传送、终止连接**三个步骤。TCP通信模型中，在通信开始之前，一定要先 **建立相关的链接**，才能发送数据 ，类似于生活中，"**打电话**"；而UDP通信模型中，在通信开始之前，不需要建立相关的连接，只需要发送数据即可，类似于生活中，"**写信**" 

<img src="https://user-images.githubusercontent.com/51505633/79089039-2c895780-7d77-11ea-849b-f0bc63202e62.jpg" alt="tcp" style="zoom: 80%;" />

##### TCP特点

1. 面向连接

   通信双方必须先建立连接才能进行数据的传输，双方都必须为该连接分配必要的系统内核资源，以管理连接的状态和连接上的传输。

   双方间的数据传输都可以通过这一个连接进行；完成数据交换后，双方必须断开此连接，以释放系统资源。这种连接是一对一的，因此 **TCP不适用于广播** 的应用程序，**基于广播**的应用程序请使用**UDP**协议。

2. 可靠传输

   - **TCP采用发送应答机制**：TCP发送的每个报文段都必须得到接收方的应答才认为这个TCP报文段传输成功

   - **超时重传**：发送端发出一个报文段之后就启动定时器，如果在定时时间内没有收到应答就重新发送这个报文段。

     TCP为了保证不发生丢包，就给每个包一个序号，同时序号也保证了传送到接收端实体的包的按序接收。然后接收端实体对已成功收到的包发回一个相应的确认（ACK）；如果发送端实体在合理的往返时延（RTT）内未收到确认，那么对应的数据包就被假设为已丢失将会被进行重传。

   - **错误校验**：TCP用一个校验和函数来检验数据是否有错误；在发送和接收时都要计算校验和。

   - **流量控制和阻塞管理**：流量控制用来避免主机发送得过快而使接收方来不及完全收下。

##### TCP与UDP的不同点

- 面向连接（确认有创建三方交握，连接已创建才作传输。）
- 有序数据传输
- 重发丢失的数据包
- 舍弃重复的数据包
- 无差错的数据传输
- 阻塞/流量控制

tcp 严格区分客户端解和服务器端，而 udp 不区分

所谓的 **服务器端** ：就是 **提供服务的一方** ，而 **客户端** ，就是需要 **被服务的一方** 

##### tcp客户端构建

示例代码：

```python
from socket
# 创建tcp socket
tcp_client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
# 目的信息
server_ip = input("请输入服务器ip:")
server_port = int(input("请输入服务器port:"))
# 链接服务器
tcp_client_socket.connect((server_ip, server_port))  # 元组
# 提示用户输入数据
send_data = input("请输入要发送的数据：")
tcp_client_socket.send(send_data.encode("gbk"))  # 因为已经链接 只需内容  send
# 接收对方发送过来的数据，最大接收1024个字节
recvData = tcp_client_socket.recv(1024)
print('接收到的数据为:', recvData.decode('gbk'))
# 关闭套接字
tcp_client_socket.close()
```

##### tcp服务器构建

想要完成一个tcp服务器的功能，需要的流程如下：

1. socket创建一个套接字
2. bind绑定ip和port
3. listen使套接字变为可以被动链接
4. accept等待客户端的链接
5. recv/send接收发送数据

```python
from socket
# 创建tcp socket
tcp_server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
# 本地信息
address = ('', 7788)
# 绑定
tcp_server_socket.bind(address)
# 使用socket创建的套接字默认的属性是主动的，使用listen将其变为被动的，这样就可以接收别人的链接了
tcp_server_socket.listen(128)
# 如果有新的客户端来链接服务器，那么就产生一个新的套接字专门为这个客户端服务
# client_socket用来为这个客户端服务
# tcp_server_socket就可以省下来专门等待其他新客户端的链接
client_socket, clientAddr = tcp_server_socket.accept()  # 返回元组 拆包
# 第一个接收 新的套接字，第二个接收 链接客户端的地址
# 新的套接字 负责客户端通信，tcp套接字 负责监听 等待新客户端链接
# 接收对方发送过来的数据
recv_data = client_socket.recv(1024)  # 接收1024个字节 返回只有数据
print('接收到的数据为:', recv_data.decode('gbk'))
# 发送一些数据到客户端
client_socket.send("thank you !".encode('gbk'))
# 关闭为这个客户端服务的套接字，只要关闭了，就不能再为这个客户端服务，如果还需要服务，只能再次重新连接
client_socket.close()
tcp_server_socket.close()
```

用 如果想让别人能更够打通咱们的电话获取相应服务 类比，需要做以下几件事情：

1. 买个手机  ——  创建套接字
2. 插上手机卡  ——  绑定ip和port
3. 设计手机为正常接听状态（即能够响铃）  ——  变为被动链接
4. 静静的等着别人拨打  ——  等待客户端链接

客户端调用 connect() 时 会 解 accept() 的堵塞

 recv解堵塞，有2种方式：客户端发送过来数据 / 客户端调用close

```python
# 循环为多个客户端服务并且多次服务一个客户端
import socket
# 1. 买个手机(创建套接字 socket)
tcp_server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
# 2. 插入手机卡(绑定本地信息 bind)
tcp_server_socket.bind(("", 7890))
# 3. 将手机设置为正常的 响铃模式(让默认的套接字由主动变为被动 listen)
tcp_server_socket.listen(128)
# 循环目的：调用多次accept,从而为多个客户端服务
while True:
    print("等待一个新的客户端的到来...")
    # 4. 等待别人的电话到来(等待客户端的链接 accept)
    new_client_socket, client_addr = tcp_server_socket.accept()
    print("一个新的客户端已经到来%s" % str(client_addr))
    # 循环目的: 为同一个客户端 服务多次
    while True:
        # 接收客户端发送过来的请求
        recv_data = new_client_socket.recv(1024)
        print("客户端福送过来的请求是:%s" % recv_data.decode("utf-8"))
        # 如果recv解堵塞，那么有2种方式：
        # 1. 客户端发送过来数据
        # 2. 客户端调用close导致了 这里 recv解堵塞
        # 客户端不能发送空的内容 因此，若recv_data 为空，则一定是 客户端调用close
        if recv_data:
            # 回送一部分数据给客户端
            new_client_socket.send("hahahghai-----ok-----".encode("utf-8"))
        else:
            break
    # 关闭套接字
    # 关闭accept返回的套接字 意味着 不会在为这个客户端服务
    new_client_socket.close()
    print("已经为这个客户端服务完毕。。。。")
# 如果将监听套接字 关闭了，那么会导致 不能再次等待新客户端的到来，即xxxx.accept就会失败
tcp_server_socket.close()
```

##### 案例：文件下载

见项目文件 `file_download_client.py` 和 `file_download_server.py`

with 打开文件时，可以在打得开的情况下，出现异常，调用close()；但如果打不开文件，则用with 也会报异常。写时没有关系，文件不存在等情况，会新建文件。读的时候，文件不一定存在，使用with  不合适。

#### 小结

**udp 用来收数据 需 bind，tcp client 一般不需要 bind**

> qq 不绑定端口时 可通过服务器转发。服务器可以获得所有请求的地址。 QQ既有UDP也有TCP 

**客户端**要绑定端口，可能会在多开或端口被占用时出错，因此，**一般不绑定**。

**tcp注意点**：

1. tcp服务器一般情况下都需要绑定，否则客户端找不到这个服务器
2. tcp客户端一般不绑定，因为是主动链接服务器，所以只要确定好服务器的ip、port等信息就好，本地客户端可以随机
3. tcp服务器中通过listen可以将socket创建出来的主动套接字变为被动的，这是做tcp服务器时必须要做的
4. 当客户端需要连接服务器时，就需要使用connect进行连接，udp是不需要链接的而是直接发送，但是tcp必须先连接，只有连接成功才能通信
5. 当一个tcp客户端连接服务器时，服务器端会有1个新的套接字，这个套接字用来标记这个客户端，单独为这个客户端服务
6. listen后的套接字是被动套接字，用来接收新的客户端的链接请求的，而accept返回的新套接字是标记这个新客户端的
7. 关闭listen后的套接字意味着被动套接字关闭了，会导致新的客户端不能够链接服务器，但是之前已经链接成功的客户端正常通信。
8. 关闭accept返回的套接字意味着这个客户端已经服务完毕
9. 当客户端的套接字调用close后，服务器端会recv解堵塞，并且返回的长度为0，因此服务器可以通过返回数据的长度来区别客户端是否已经下线

### 1 多任务

现在，多核CPU已经非常普及了，但是，即使过去的单核CPU，也可以执行多任务。由于CPU执行代码都是顺序执行的，那么，单核CPU是怎么执行多任务的呢？

答案就是操作系统轮流让各个任务交替执行，任务1执行0.01秒，切换到任务2，任务2执行0.01秒，再切换到任务3，执行0.01秒……这样反复执行下去。表面上看，每个任务都是交替执行的，但是，由于CPU的执行速度实在是太快了，我们感觉就像所有任务都在同时执行一样。（**时间片轮转**）

真正的并行执行多任务只能在多核CPU上实现，但是，由于任务数量远远多于CPU的核心数量，所以，操作系统也会自动把很多任务轮流调度到每个核心上执行。

##### 并发与并行

- 并发：指的是**任务数多余cpu核数**，通过操作系统的各种任务**调度算法**，实现用多个任务“一起”执行（实际上总有一些任务不在执行，因为切换任务的速度相当快，看上去一起执行而已）
- 并行：指的是**任务数小于等于cpu核数**，即任务真的是一起执行的

#### 线程

python的thread模块是比较底层的模块，python的 **threading模块**是对thread做了一些包装的，可以更加方便的被使用

单线程执行

```python
import time
def saySorry():
    print("我能吃饭了吗？")
    time.sleep(1)
if __name__ == "__main__":
    for i in range(5):
        saySorry()
```

多线程执行

```python
import threading
import time
def saySorry():
    print("我能吃饭了吗？")
    time.sleep(1)
if __name__ == "__main__":
    for i in range(5):
        t = threading.Thread(target=saySorry)  # 函数名
        t.start() #启动线程，即让线程开始执行
```

1. 可以明显看出使用了多线程并发的操作，花费时间要短很多
2. 当调用`start()`时，才会真正的创建线程，并且开始执行

##### 主线程等待所有的子线程结束

主线程执行到没有代码时，**会等待所有的子线程结束后才结束**，主线程结束后，整个程序结束

> 原来默认的执行顺序相当于主线程，创建的是子线程，从函数开始执行。

```python
import threading
from time import sleep,ctime
def sing():
    for i in range(3):
        print("正在唱歌...%d"%i)
        sleep(1)
def dance():
    for i in range(3):
        print("正在跳舞...%d"%i)
        sleep(1)
print('---开始---:%s'%ctime())
t1 = threading.Thread(target=sing)
t2 = threading.Thread(target=dance)
t1.start()
t2.start()
print(threading.enumerate())  # enumerate() 返回list，为 所有的线程
sleep(5)  # 注释此行代码，试试看，程序是否会立马结束？
# 注释后，主线程会将下面所有代码执行完后等待子进程结束
print('---结束---:%s'%ctime())
print(threading.enumerate())
```

##### 查看线程数量

```python
import threading
from time import sleep,ctime
def sing():
    for i in range(3):
        print("正在唱歌...%d"%i)
        sleep(1)
def dance():
    for i in range(3):
        print("正在跳舞...%d"%i)
        sleep(1)
print('---开始---:%s'%ctime())
t1 = threading.Thread(target=sing)
t2 = threading.Thread(target=dance)
t1.start()
t2.start()
while True:
    length = len(threading.enumerate())
    print('当前运行的线程数为：%d'%length)
    if length<=1:
        break
    sleep(0.5)
```

线程的运行没有先后顺序！多线程的执行顺序不确定，可通过适当延时，保证线程执行顺序

```python
import threading
import time
def test1():
    for i in range(5):
        print("-----test1---%d---" % i)
def test2():
    for i in range(5):
        print("-----test2---%d---" % i)
t1 = threading.Thread(target=test1)
t2 = threading.Thread(target=test2)
t1.start()
time.sleep(1)  # 先令t1线程执行完
print("---1---")
t2.start()
time.sleep(1)  # 再令t2线程执行完
print("---2---")
print(threading.enumerate())
```

如果创建Thread时执行的函数，运行结束，那么意味着 这个子线程结束了(示例程序中只需要看list长度)

```python
import threading
import time
def test1():
    for i in range(5):
        print("-----test1---%d---" % i)
        time.sleep(1)
    # 如果创建Thread时执行的函数，运行结束那么意味着 这个子线程结束了....
def test2():
    for i in range(10):
        print("-----test2---%d---" % i)
        time.sleep(1)
t1 = threading.Thread(target=test1)
t2 = threading.Thread(target=test2)
t1.start()
t2.start()
while True:
    print(threading.enumerate())
    if len(threading.enumerate())<=1:
        break
    time.sleep(1)
```

**子线程在调用Thread创建的实例对象的 start() 方法时才会 创建线程 并让线程开始运行，threading.Thread 不会创建线程**，只是一个对象

```python
# 验证什么时候创建线程，什么时候线程执行
# 创建线程：线程list 有两个值；线程执行：输出test1中的print语句
import threading
import time
def test1():
    for i in range(5):
        print("-----test1---%d---" % i)
        time.sleep(1)
print(threading.enumerate())  # 在调用Thread之前先打印当前线程信息
t1 = threading.Thread(target=test1)
print(threading.enumerate())  # 在调用Thread之后打印
t1.start()
time.sleep(2)
print(threading.enumerate())  # 在调用start之后打印
```

##### 创建线程方式

- 函数：Thread(target=saySorry)   —— 线程执行函数中代码
- 类：定义类 继承 Thread 。继承 Thread 时，必须定义 run() 方法，调用 start() 时 会自动调用 run()  —— 线程执行run中代码

```python
# 线程执行代码的封装   
import threading
import time
class MyThread(threading.Thread):
    def run(self):
        for i in range(3):
            time.sleep(1)
            msg = "I'm "+self.name+' @ '+str(i)  # name属性中保存的是当前线程的名字，自动指定
            print(msg)
def test():
    for i in range(5):
        t = MyThread()
        t.start()
test()
```

说明：

- python的threading.Thread类有一个run方法，用于定义线程的功能函数，可以在自己的线程类中覆盖该方法。而创建自己的线程实例后，通过Thread类的start方法，可以启动该线程，交给python虚拟机进行调度，当该线程获得执行的机会时，就会调用run方法执行线程。当线程的run()方法结束时该线程完成。
-  从代码和执行结果我们可以看出，多线程程序的执行顺序是不确定的。当执行到sleep语句时，线程将被阻塞（Blocked），到sleep结束后，线程进入就绪（Runnable）状态，等待调度。而线程调度将自行选择一个线程执行。上面的代码中只能保证每个线程都运行完整个run函数，但是线程的启动顺序、run函数中每次循环的执行顺序都不能确定。 

##### 多线程共享全局变量

在函数中 对全局变量进行修改时，是否需要使用 global ，需要看是否对全局变量的指向进行修改；如果修改了指向，即让全局变量指向了新的内存地址，则必须使用 global ；如果仅仅修改了指向的空间中的数据，则不必使用 global

```python
# 这使用了两种传变量方式 -- 直接用（全局变量） / 通过 线程的args参数    虽然这g_nums 也是全局变量
import threading
import time
g_num = 100
g_nums = [11, 22]
def test1(temp):
    global g_num
    g_num += 99
    temp.append(33)
    print("-----in test1 g_num=%d, temp=%s----" % (g_num, str(temp)))
def test2(temp):
    print("-----in test2 g_num=%d, temp=%s----" % (g_num, str(temp)))
def main():
    # target指定将来 这个线程去哪个函数执行代码
    # args指定将来调用 函数的时候 传递什么数据过去
    t1 = threading.Thread(target=test1, args=(g_nums,))  # args 参数为元组，所以有，
    t2 = threading.Thread(target=test2, args=(g_nums,))
    t1.start()
    time.sleep(1)
    t2.start()
    time.sleep(1)
    print("-----in main Thread g_num=%d, g_nums=%s----" % (g_num, str(g_nums)))
if __name__ == "__main__":
    main()
```

##### 资源竞争问题

多线程开发可能遇到的问题：如果**多个线程同时**对**同一个全局变量操作**，会出现**资源竞争问题**，从而数据结果会不正确。

示例：

> 假设两个线程t1和t2都要对全局变量g_num(默认是0)进行加1运算，t1和t2都各对g_num加10次，g_num的最终的结果应该为20。但是由于是多线程同时操作，有可能出现下面情况：
>
> 1. 在g_num=0时，t1取得g_num=0。此时系统把t1调度为”sleeping”状态，把t2转换为”running”状态，t2也获得g_num=0
> 2. 然后t2对得到的值进行加1并赋给g_num，使得g_num=1
> 3. 然后系统又把t2调度为”sleeping”，把t1转为”running”。线程t1又把它之前得到的0加1后赋值给g_num。
> 4. 这样导致虽然t1和t2都对g_num加1，但结果仍然是g_num=1

```python
import threading
import time
g_num = 0
def work1(num):
    global g_num
    for i in range(num):
        g_num += 1
    print("----in work1, g_num is %d---"%g_num)
def work2(num):
    global g_num
    for i in range(num):
        g_num += 1
    print("----in work2, g_num is %d---"%g_num)
print("---线程创建之前g_num is %d---"%g_num)
t1 = threading.Thread(target=work1, args=(1000000,))
t1.start()
t2 = threading.Thread(target=work2, args=(1000000,))
t2.start()
while len(threading.enumerate()) != 1:
    time.sleep(1)
print("2个线程对同一个全局变量操作之后的最终结果是:%s" % g_num)
# 运行结果：
# ---线程创建之前g_num is 0---
# ----in work1, g_num is 1088005---
# ----in work2, g_num is 1286202---
# 2个线程对同一个全局变量操作之后的最终结果是:1286202
```

##### 同步

同步就是协同步调，按预定的先后次序进行运行。  如进程、线程同步，可理解为进程或线程A和B一块配合，A执行到一定程度时要依靠B的某个结果，于是停下来，示意B运行;B执行，再将结果给A;A再继续操作。 

##### 互斥锁

- 当多个线程几乎同时修改某一个共享数据的时候，需要进行同步控制
- 线程同步能够保证多个线程安全访问竞争资源，最简单的同步机制是引入互斥锁。
- 互斥锁为资源引入一个状态：锁定/非锁定

某个线程要更改共享数据时，先将其锁定，此时资源的状态为“锁定”，其他线程不能更改；直到该线程释放资源，将资源的状态变成“非锁定”，其他的线程才能再次锁定该资源。互斥锁保证了每次只有一个线程进行写入操作，从而保证了多线程情况下数据的正确性。

threading模块中定义了Lock类，可以方便的处理锁定：

```python
mutex = threading.Lock()  # 创建互斥锁 默认没有上锁 上锁只能上一次
mutex.acquire()  # 锁定
mutex.release()  # 释放
```

注意：

- 如果这个锁之前是没有上锁的，那么acquire不会堵塞
- 如果在调用acquire对这个锁上锁之前 它已经被 其他线程上了锁，那么此时acquire会堵塞，直到这个锁被解锁为止
- 上锁的代码越少越好

>  谁先上锁，谁先做事情；谁后上锁，谁就做不了    上厕所，锁门后，外边只能排队等

示例的解决：

```python
import threading
import time
g_num = 0  # 定义一个全局变量
def test1(num):
    global g_num
    # 上锁，如果之前没有被上锁，那么此时 上锁成功
    # 如果上锁之前 已经被上锁了，那么此时会堵塞在这里，直到 这个锁被解开位置
    for i in range(num):
        mutex.acquire()  # 上锁 如果都在for外面上锁，会执行完整个for循环，不符合 上锁的代码越少越好
        g_num += 1
        mutex.release()  # 解锁
    print("-----in test1 g_num=%d----" % g_num)
def test2(num):
    global g_num
    for i in range(num):
        mutex.acquire()  # 上锁
        g_num += 1
        mutex.release()  # 解锁
    print("-----in test2 g_num=%d=----" % g_num)
mutex = threading.Lock()  # 创建一个互斥锁，默认是没有上锁的
def main():
    t1 = threading.Thread(target=test1, args=(1000000,))
    t2 = threading.Thread(target=test2, args=(1000000,))
    t1.start()
    t2.start()
    # 等待上面的2个线程执行完毕....
    time.sleep(2)
    print("-----in main Thread g_num = %d---" % g_num)
if __name__ == "__main__":
    main()
# 运行结果：
# ---test1---g_num=1920255
# ---test2---g_num=2000000
# 2个线程对同一个全局变量操作之后的最终结果是:2000000
```

##### 死锁

在线程间共享多个资源的时候，如果两个线程分别占有一部分资源并且同时等待对方的资源，就会造成死锁。 

示例：

```python
import threading
import time
class MyThread1(threading.Thread):
    def run(self):
        mutexA.acquire()  # 对mutexA上锁
        # mutexA上锁后，延时1秒，等待另外那个线程 把mutexB上锁
        print(self.name+'----do1---up----')
        time.sleep(1)
        mutexB.acquire()  # 此时会堵塞，因为这个mutexB已经被另外的线程抢先上锁了
        print(self.name+'----do1---down----')
        mutexB.release()
        mutexA.release()  # 对mutexA解锁
class MyThread2(threading.Thread):
    def run(self):
        mutexB.acquire()  # 对mutexB上锁
        # mutexB上锁后，延时1秒，等待另外那个线程 把mutexA上锁
        print(self.name+'----do2---up----')
        time.sleep(1)
        mutexA.acquire()  # 此时会堵塞，因为这个mutexA已经被另外的线程抢先上锁了
        print(self.name+'----do2---down----')
        mutexA.release()
        mutexB.release()  # 对mutexB解锁
mutexA = threading.Lock()
mutexB = threading.Lock()
if __name__ == '__main__':
    t1 = MyThread1()
    t2 = MyThread2()
    t1.start()
    t2.start()
```

避免死锁：设计时避免（银行家算法） /  添加超时时间等

##### 银行家算法 

银行家算法是从当前状态出发，逐个按安全序列检查各客户谁能完成其工作，然后假定其完成工作且归还全部贷款，再进而检查下一个能完成工作的客户，......。如果所有客户都能完成工作，则找到一个安全序列，银行家才是安全的。 

##### 案例：多任务版UTP聊天器

> 需求：
>
> - 编写一个有2个线程的程序
> - 线程1用来接收数据然后显示
> - 线程2用来检测键盘数据然后通过udp发送数据

实现：`udp_threading_app.py` 文件

##### 小结

1. 多任务：实现多个程序(函数等)可以一起运行
2. 线程是实现多任务的一种基本方式，轻量级
3. 导入 threading.Thread 类，创建实例对象，在调用start()时创建线程，并从创建对象时指定的target(函数引用)处开始执行，函数执行完，线程结束
4. 线程执行顺序不确定；多线程的调度由操作系统(/调度算法)决定；主线程最后结束
5. 通过 程序设计/互斥锁 方式，避免共享全局变量时资源竞争问题
6. 互斥锁 可能 导致 死锁

#### 进程

程序：例如xxx.py这是程序，是一个静态的

进程：一个程序运行起来后，**代码 +** 用到的**资源** 称之为进程，它是操作系统**分配资源**的**基本单元**。

不仅可以通过线程完成多任务，进程也可以

##### 进程的状态

工作中，任务数往往大于cpu的核数，即一定有一些任务正在执行，而另外一些任务在等待cpu进行执行，因此导致了有了不同的状态。

<img src="https://user-images.githubusercontent.com/51505633/79089066-462a9f00-7d77-11ea-8c9b-428f4ab202df.jpg" alt="process" style="zoom:50%;" />

- 就绪态：运行的条件都已经慢去，正在等在cpu执行
- 执行态：cpu正在执行其功能
- 等待态：等待某些条件满足，例如一个程序sleep了，此时就处于等待态

##### 进程的创建 - multiprocessing

multiprocessing模块就是跨平台版本的多进程模块，提供了一个Process类来代表一个进程对象，这个对象可以理解为是一个独立的进程，可以执行另外的事情 

```python
import time
import multiprocessing
def test1():
    while True:
        print("----1----")
        time.sleep(1)
def test2():
    while True:
        print("----2----")
        time.sleep(1)
if __name__ == "__main__":  # 必须有这个语句，不然报错 RuntimeError
    p1 = multiprocessing.Process(target=test1)
    p2 = multiprocessing.Process(target=test2)
    p1.start()
    p2.start()
    while True:
        print("----0----")
        time.sleep(1)
```

创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用start()方法启动

调用 start() 时子进程创建，与主进程共享一样的 代码和资源，不能共享的会复制 —— **写时拷贝**

**具体如何处理？**

> 由于Python运行过程中，新创建进程后，进程会导入正在运行的文件，即在运行代码时，运行到mp.Process，新的进程会重新读入该代码，对于没有 `if __name__=="__main__":` 保护的代码，新进程都认为是要再次运行的代码，这是子进程又一次运行mp.Process，但是在multiprocessing.Process的源码中是对子进程再次产生子进程是做了限制的，是不允许的，于是出现如上的错误提示。 
>
> 当代码被当做脚本读入的时候，命名空间会被命名为 `"main"`，对于在脚本运行过程中读入的代码命名空间都不会被命名为 `"main"`。这也就是说创建的子进程是不会读取 `if __name__=="__main__":` 保护下的代码。 

##### 进程pid

```python
# -*- coding:utf-8 -*-
from multiprocessing import Process
import os
import time
def run_proc():
    """子进程要执行的代码"""
    while True:
        print("--子进程 pid=%d >2> 父进程pid=%d--" % (os.getpid(), os.getppid()))
        time.sleep(1)
if __name__ == '__main__':
    print("--主进程 pid=%d >0> 父进程pid=%d--" % (os.getpid(), os.getppid()))
    # os.getpid()获取当前进程id     os.getppid()获取父进程id
    p = Process(target=run_proc)
    p.start()
    while True:
        print("--主进程 pid=%d >1> 父进程pid=%d--" % (os.getpid(), os.getppid()))
        time.sleep(1)
```

(VScode中)主程序的父进程id为执行程序的终端的进程号，主进程和子进程都为 Python 解释器

> 强制结束一个进程时，其他进程继续运行，强制结束所有进程后，**命令行阻塞**；但如果主进程已经运行结束(非无限循环)，强制结束子进程后，代码运行终止。

##### Process 语法结构

`Process([group [, target [, name [, args [, kwargs]]]]])`：

- `target`：如果传递了函数的引用，可以任务这个子进程就执行这里的代码
- `args`：给target指定的函数传递的参数，以元组的方式传递
- `kwargs`：给target指定的函数传递命名参数
- `name`：给进程设定一个名字，可以不设定
- `group`：指定进程组，大多数情况下用不到

Process创建的实例对象的常用方法：

- `start()`：启动子进程实例（创建子进程）
- `is_alive()`：判断进程子进程是否还在活着
- `join([timeout])`：是否等待子进程执行结束，或等待多少秒
- `terminate()`：不管任务是否完成，立即终止子进程

Process创建的实例对象的常用属性：

- `name`：当前进程的别名，默认为Process-N，N为从1开始递增的整数
- `pid`：当前进程的pid（进程号）

进程的执行顺序不固定，但主进程会等待子进程执行完毕

##### 给子进程指定的函数传递参数

```python
# -*- coding:utf-8 -*-
from multiprocessing import Process
import os
from time import sleep
def run_proc(name, age, *args, **kwargs):
    for i in range(10):
        print('子进程运行中，name=%s,age=%d ,pid=%d...' % (name, age, os.getpid()))
        print(args)
        print(kwargs)
        sleep(0.2)
if __name__=='__main__':
    p = Process(target=run_proc, args=('test',18,11,22,33), kwargs={"m":20})
    p.start()
    sleep(1)  # 1秒中之后，立即结束子进程
    p.terminate()
    p.join()
```

##### 多进程间不共享全局变量

```python
# -*- coding:utf-8 -*-
from multiprocessing import Process
import os
import time
nums = [11, 22]
def work1():
    """子进程要执行的代码"""
    print("in process1 pid=%d ,nums=%s" % (os.getpid(), nums))
    nums.append(33)
    time.sleep(1)
    print("in process1 pid=%d ,nums=%s" % (os.getpid(), nums))
def work2():
    """子进程要执行的代码"""
    print("in process2 pid=%d ,nums=%s" % (os.getpid(), nums))
if __name__ == '__main__':
    p1 = Process(target=work1)
    p1.start()
    p1.join()
    p2 = Process(target=work2)
    p2.start()
```

##### 进程、线程对比

###### 功能

- 进程，能够完成多任务，比如 在一台电脑上能够同时运行多个QQ
- 线程，能够完成多任务，比如 一个QQ中的多个聊天窗口

###### 定义

- **进程**是系统进行**资源分配和调度**的一个**独立单位**.
- **线程**是**进程**的一个**实体**,是**CPU调度和分派的基本单位**,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源.

###### 区别

- **一个程序**至少有**一个进程**,一个进程至少有**一个线程**。
- 线程的划分尺度小于进程(资源比进程少)，使得多线程程序的并发性高。
- **进程**在执行过程中拥有**独立**的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。
- **线程不能够独立执行**，必须依存在进程中。

可以将进程理解为工厂中的一条流水线，而其中的线程就是这个流水线上的工人

###### 优缺点

线程和进程在使用上各有优缺点：线程执行开销小，但不利于资源的管理和保护；而进程正相反。

##### 进程间通信 - Queue 队列

> socket 也可以实现进程间通信

##### Queue 的使用

可以使用multiprocessing模块的Queue实现多进程之间的数据传递，Queue本身是一个消息列队程序，示例：

```python
from multiprocessing import Queue
q = Queue(3)  # 初始化一个Queue对象，最多可接收三条put消息
q.put("消息1") 
q.put("消息2")
print(q.full())  # False
q.put("消息3")
print(q.full())  # True
# 因为消息列队已满下面的try都会抛出异常，第一个try会等待2秒后再抛出异常，第二个Try会立刻抛出异常
try:
    q.put("消息4",True,2)
except:
    print("消息列队已满，现有消息数量:%s"%q.qsize())
try:
    q.put_nowait("消息4")
except:
    print("消息列队已满，现有消息数量:%s"%q.qsize())
# 推荐的方式，先判断消息列队是否已满，再写入
if not q.full():
    q.put_nowait("消息4")
# 读取消息时，先判断消息列队是否为空，再读取
if not q.empty():
    for i in range(q.qsize()):
        print(q.get_nowait())
```

> 初始化Queue()对象时（例如：q=Queue()），若括号中没有指定最大可接收的消息数量，或数量为负值，那么就代表可接受的消息数量没有上限（直到内存的尽头）；
>
> - **Queue.qsize()**：返回当前队列包含的消息数量；
>
> - **Queue.empty()**：如果队列为空，返回True，反之False ；
>
> - **Queue.full()**：如果队列满了，返回True,反之False；
>
> - **Queue.get([block[, timeout]])**：获取队列中的一条消息，然后将其从列队中移除，block默认值为True；
>
>     1）如果block使用默认值，且没有设置timeout（单位秒），消息列队如果为空，此时程序将被阻塞（停在读取状态），直到从消息列队读到消息为止，如果设置了timeout，则会等待timeout秒，若还没读取到任何消息，则抛出"Queue.Empty"异常；
>
>     2）如果block值为False，消息列队如果为空，则会立刻抛出"Queue.Empty"异常；
>
> - **Queue.get_nowait()**：相当Queue.get(False)；
>
> - **Queue.put(item,[block[, timeout]])**：将item消息写入队列，block默认值为True；
>
>     1）如果block使用默认值，且没有设置timeout（单位秒），消息列队如果已经没有空间可写入，此时程序将被阻塞（停在写入状态），直到从消息列队腾出空间为止，如果设置了timeout，则会等待timeout秒，若还没空间，则抛出"Queue.Full"异常；
>
>     2）如果block值为False，消息列队如果没有空间可写入，则会立刻抛出"Queue.Full"异常；
>
> - **Queue.put_nowait(item)**：相当Queue.put(item, False)；

##### 多进程通过Queue实现数据共享

一个进程向Queue中写入数据，另外一个进程从Queue中获取数据，通过**Queue**完成了 多个需要配合的进程间的数据共享，从而能够 起到 **解耦**的作用

```python
import multiprocessing
def download_from_web(q):
    """下载数据"""
    # 模拟从网上下载的数据
    data = [11, 22, 33, 44]
    # 向队列中写入数据
    for temp in data:
        q.put(temp)
    print("---下载器已经下载完了数据并且存入到队列中----")
def analysis_data(q):
    """数据处理"""
    waitting_analysis_data = list()  # 同 []，但可读性更强
    # 从队列中获取数据
    while True:
        data = q.get()
        waitting_analysis_data.append(data)
        if q.empty():
            break
    # 模拟数据处理
    print(waitting_analysis_data)
# 1. 创建一个队列
q = multiprocessing.Queue()
# 2. 创建多个进程，将队列的引用当做实参进行传递到里面
p1 = multiprocessing.Process(target=download_from_web, args=(q,))
p2 = multiprocessing.Process(target=analysis_data, args=(q,))
p1.start()
p2.start()
```

Queue 只能用于同一个电脑的同一个程序的多个进程，Redis 可以实现消息队列，实现分布式。

##### 进程池 Pool

用multiprocessing模块提供的Pool方法，创建多个子进程。

初始化Pool时，可以指定一个最大进程数，当有新的请求提交到Pool中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到指定的最大值，那么该请求就会等待，直到池中有进程结束，才会用之前的进程来执行新的任务。

进程数量很少或确定时，不需要使用进程池；很多或不确定时，使用进程池

```python
# -*- coding:utf-8 -*-
from multiprocessing import Pool
import os, time, random
def worker(msg):
    t_start = time.time()
    print("%s开始执行,进程号为%d" % (msg,os.getpid()))
    # random.random()随机生成0~1之间的浮点数
    time.sleep(random.random()*2) 
    t_stop = time.time()
    print(msg,"执行完毕，耗时%0.2f" % (t_stop-t_start))
if __name__ == '__main__':
    po = Pool(3)  # 定义一个进程池，最大进程数3
    # 非现在创建子进程，在使用时创建子进程
    for i in range(0,10):
        # Pool().apply_async(要调用的目标,(传递给目标的参数元祖,))
        # 每次循环将会用空闲出来的子进程去调用目标
        po.apply_async(worker,(i,))  # 要执行的任务 函数名
    print("----start----")
    po.close()  # 关闭进程池，关闭后po不再接收新的请求
    po.join()  # 等待po中所有子进程执行完成，必须放在close语句之后
    print("-----end-----")
```

主进程 不会等待 进程池中的创建的子进程 执行完毕，需要阻塞，使其等待

##### Pool 常用函数

- `apply_async(func[, args[, kwds]])` ：使用非阻塞方式调用func（并行执行，堵塞方式必须等待上一个进程退出才能执行下一个进程），args为传递给func的参数列表，kwds为传递给func的关键字参数列表；
- `close()`：关闭Pool，使其不再接受新的任务；
- `terminate()`：不管任务是否完成，立即终止；
- `join()`：主进程阻塞，等待子进程的退出， 必须在close或terminate之后使用；

##### 进程池中的 Queue

如果要使用Pool创建进程，就需要使用multiprocessing.Manager()中的Queue()，而不是multiprocessing.Queue()

```python
# 修改import中的Queue为Manager
from multiprocessing import Manager,Pool
import os,time,random
def reader(q):
    print("reader启动(%s),父进程为(%s)" % (os.getpid(), os.getppid()))
    for i in range(q.qsize()):
        print("reader从Queue获取到消息：%s" % q.get(True))
def writer(q):
    print("writer启动(%s),父进程为(%s)" % (os.getpid(), os.getppid()))
    for i in "itcast":
        q.put(i)
if __name__=="__main__":
    print("(%s) start" % os.getpid())
    q = Manager().Queue()  # 使用Manager中的Queue
    po = Pool()
    po.apply_async(writer, (q,))
    time.sleep(1)  # 先让上面的任务向Queue存入数据，然后再让下面的任务开始从中取数据
    po.apply_async(reader, (q,))
    po.close()
    po.join()
    print("(%s) End" % os.getpid())
```

> 如果进程池中产生异常，不会输出异常信息。

##### 案例：文件夹 copy 器

实现：`dir_copy_process.py` 文件

 \r 默认将指针返回到最开始后输出（*在原位置再次输出*）

#### 协程

##### 迭代器 

> 迭代是访问集合元素的一种方式。迭代器是一个可以记住遍历的位置的对象。迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。

###### 可迭代对象 Iterable

可以对list、tuple、str等类型的数据使用for...in...的循环语法从其中依次拿到数据进行使用，我们把这样的过程称为遍历，也叫**迭代**。

**但是，是否所有的数据类型都可以放到for...in...的语句中，然后让for...in...每次从中取出一条数据供我们使用，即供我们迭代吗？**

```python
# MyList 的目的 --> 自己实现一个额可迭代的对象
# 我们自定义一个容器MyList用来存放数据，可以通过add方法向其中添加数据
class MyList(object):
    def __init__(self):
            self.container = []
    def add(self, item):
            self.container.append(item)
mylist = MyList()
mylist.add(1)
mylist.add(2)
mylist.add(3)
for num in mylist:
    print(num)
# TypeError: 'MyList' object is not iterable
```

自定义了一个容器类型MyList，在将一个存放了多个数据的MyList对象放到for...in...的语句中，发现for...in...并不能从中依次取出一条数据返回给我们，也就说我们随便封装了一个可以存放多条数据的类型却并不能被迭代使用。 

把可以通过for...in...这类语句迭代读取一条数据供我们使用的对象称之为**可迭代对象（Iterable）**。 

###### 如何判断一个对象是否可以迭代

使用 isinstance() 判断一个对象是否是 Iterable 对象

```python
from collections import Iterable  # Iterable 是一个类
print(isinstance([], Iterable))  # True    isinstance 判断是不是一个实例
print(isinstance('abc', Iterable))  # True
print(isinstance(mylist, Iterable))  # False
print(isinstance(100, Iterable))  # False
```

###### 可迭代对象的本质

对可迭代对象进行迭代使用的过程，发现每迭代一次（即在for...in...中每循环一次）都会返回对象中的下一条数据，一直向后读取数据直到迭代了所有数据后结束。那么，在这个过程中就应该有一个“人”去记录每次访问到了第几条数据，以便每次迭代都可以返回下一条数据。我们把这个能帮助我们进行数据迭代的“人”称为**迭代器(Iterator)**。 

**可迭代对象的本质**就是可以向我们**提供**一个这样的中间“人”即**迭代器**帮助我们对其**进行迭代遍历**使用。 

可迭代对象通过`__iter__`方法向我们提供一个迭代器，我们在迭代一个可迭代对象的时候，实际上就是先获取该对象提供的一个迭代器，然后通过这个迭代器来依次获取对象中的每一个数据.

**也就是说，一个具备了`__iter__`方法的对象，就是一个可迭代对象。**

```python
from collections import Iterable
class MyList(object):
    def __init__(self):
        self.container = []
    def add(self, item):
        self.container.append(item)
    def __iter__(self):  # 如果想要一个对象成为一个可迭代的对象，即可使用for，那么必须实现__iter__方法
        """必须返回一个具有__iter__和__next__方法的引用 —— 迭代器对象"""
        pass  # 我们暂时忽略如何构造一个迭代器对象
mylist = MyList()
print("判断mylist是否是可以迭代的对象:", isinstance(mylist, Iterable))  # True    print里面是一个元组
for num in mylist:
    print(num)
# iter() returned non-iterator of type 'NoneType'
```

添加了 `__iter__` 方法的 mylist 对象已经是一个可迭代对象了

###### iter()函数与next()函数

**list、tuple等都是可迭代对象，我们可以通过iter()函数获取这些可迭代对象的迭代器。然后我们可以对获取到的迭代器不断使用next()函数来获取下一条数据。**iter()函数实际上就是调用了可迭代对象的`__iter__`方法。 

```python
li = [11, 22, 33, 44, 55]
li_iter = iter(li)
print(next(li_iter))  # 11
# ... 省略
print(next(li_iter))  # 55
print(next(li_iter))  # StopIteration
```

当我们已经迭代完最后一个数据之后，再次调用next()函数会抛出StopIteration的异常，来告诉我们所有数据都已迭代完成，不用再执行next()函数了。

###### 如何判断一个对象是否是迭代器

使用 isinstance() 判断一个对象是否是 Iterator 对象 

```python
from collections import Iterator
print(isinstance([], Iterator))  # False
print(isinstance(iter([]), Iterator))  # True
print(isinstance(iter("abc"), Iterator))  # True
```

###### 迭代器 Iterator

迭代器是用来帮助我们记录每次迭代访问到的位置，当我们对迭代器使用next()函数的时候，迭代器会向我们返回它所记录位置的下一个位置的数据。实际上，在使用next()函数的时候，调用的就是迭代器对象的`__next__`方法（Python3中是对象的`__next__`方法，Python2中是对象的next()方法）。**所以，我们要想构造一个迭代器，就要实现它的`__next__`方法**。但这还不够，python要求迭代器本身也是可迭代的，所以我们还要为迭代器实现`__iter__`方法，而`__iter__`方法要返回一个迭代器，迭代器自身正是一个迭代器，所以迭代器的`__iter__`方法返回自身即可。

**一个实现了`__iter__`方法和`__next__`方法的对象，就是迭代器。**

```python
import time
from collections import Iterator
class MyList(object):
    """自定义的一个可迭代对象"""
    def __init__(self):
        self.items = []
    def add(self, val):
        self.items.append(val)
    def __iter__(self):
        return MyIterator()  # 创建了一个实例对象，返回对象的引用  这样就满足for条件了
        # 先执行右边 创建实例对象，然后把对象的引用返回
class MyIterator(object):
    """自定义的供上面可迭代对象使用的一个迭代器"""
    def __next__(self):  # 必须有的方法
        # pass
        return 111
    def __iter__(self):  # 必须有的方法
        pass
if __name__ == '__main__':
    mylist = MyList()
    mylist.add(1)
    mylist.add(2)
    mylist.add(3)
    # iter(mylist)  # 自动调用__iter__方法，得到返回值 返回的是一个迭代器（具有 两个必须有的方法）
    mylist_iterator = iter(mylist)
    print("判断mylist_iterator是否是迭代器:", isinstance(mylist_iterator, Iterator))  # True
    print(next(mylist_iterator))  # 111  next函数自动调用__next__方法，得到其返回值
    for num in mylist:
        print(num)  # 会一直输出 111
        time.sleep(1)
    # 把 __next__方法 的返回值改为 mylist 中的内容，就实现了 自己实现一个可以迭代的对象
```

`for temp in xxx_obj` 会干什么：

1. 判断 xxx_obj 是否是可迭代对象
2. 在1成立的前提下，调用iter函数，得到xxx_obj对象的`__iter__` 方法的返回值
3. `__iter__` 方法的返回值 是一个迭代器
4. for循环通过迭代器的 next函数取值，调用迭代器中的 `__next__`，返回什么，temp就是什么（这会执行多次）

```python
class MyList(object):
    """自定义的一个可迭代对象"""
    def __init__(self):
        self.items = []
    def add(self, val):
        self.items.append(val)
    def __iter__(self):
        myiterator = MyIterator(self)  # 括号中为对象的引用，为了使__next__得到self.items
        return myiterator  # 返回对象的引用
class MyIterator(object):
    """自定义的供上面可迭代对象使用的一个迭代器"""
    def __init__(self, mylist):  # mylist 就指向了MyList类的对象
        self.mylist = mylist  # 定义一个属性指向了MyList类的对象
        self.current = 0  # current用来记录当前访问到的位置 这个不能定义在__next__中  实例属性
    def __next__(self):  # 必须有的方法
        if self.current < len(self.mylist.items):  # for循环不知道何时终止，需加判断条件
            item = self.mylist.items[self.current]  # 得到了指向MyList类的对象的items列表
            self.current += 1
            return item  # 先 +1 再返回
        else:  # 没有的话 一直为 None，需自定义异常
            raise StopIteration  # 迭代器取完的异常，for会自动停止
    def __iter__(self):  # 必须有的方法
        pass
if __name__ == '__main__':
    mylist = MyList()
    mylist.add(1)
    mylist.add(2)
    mylist.add(3)
    for num in mylist:
        print(num)
# 实现了 自己实现一个可以迭代的对象
```

在 MyList 类中 `__iter__` 返回 self，省一个对象，是否可行？可行。

```python
# for 时判断类是否有__iter__(可迭代)，由于返回为自己，自己还有__next__，因此也为迭代器
# for 会调用 __iter__中返回对象的__next__方法
class MyList(object):
    """自定义的一个可迭代对象"""
    def __init__(self):
        self.items = []
        self.current = 0
    def add(self, val):
        self.items.append(val)
    def __iter__(self):
        return self
    def __next__(self):
        if self.current < len(self.items):
            item = self.items[self.current]
            self.current += 1
            return item
        else:
            raise StopIteration
if __name__ == '__main__':
    mylist = MyList()
    mylist.add(1)
    mylist.add(2)
    mylist.add(3)
    for num in mylist:
        print(num)
# 迭代器一定为可迭代对象
```

###### for...in...循环的本质

`for item in Iterable`循环的本质就是先通过iter()函数获取可迭代对象Iterable的迭代器，然后对获取到的迭代器不断调用next()方法来获取下一个值并将其赋值给item，当遇到StopIteration的异常后循环结束。 

###### 迭代器的应用场景

迭代器最核心的功能就是可以通过next()函数的调用来返回下一个数据值。如果每次返回的数据值不是在一个已有的数据集合中读取的，而是通过程序按照一定的规律计算生成的，那么也就意味着可以不用再依赖一个已有的数据集合，也就是说不用再将所有要迭代的数据都一次性缓存下来供后续依次读取，这样可以节省大量的存储（内存）空间。 

举个例子，比如，数学中有个著名的斐波拉契数列（Fibonacci），数列中第一个数为0，第二个数为1，其后的每一个数都可由前两个数相加得到：0, 1, 1, 2, 3, 5, 8, 13, 21, 34, ...

现在我们想要通过for...in...循环来遍历迭代斐波那契数列中的前n个数。那么这个斐波那契数列我们就可以用迭代器来实现，每次迭代都通过数学计算来生成下一个数。

```python
class FibIterator(object):
    """斐波那契数列迭代器"""
    def __init__(self, n):
        self.n = n  # 指明生成数列的前n个数
        self.current = 0  # current用来保存当前生成到数列中的第几个数了
        self.num1 = 0  # num1用来保存前前一个数，初始值为数列中的第一个数0
        self.num2 = 1  # num2用来保存前一个数，初始值为数列中的第二个数1
    def __next__(self):
        """被next()函数调用来获取下一个数"""
        if self.current < self.n:
            num = self.num1
            self.num1, self.num2 = self.num2, self.num1+self.num2
            self.current += 1
            return num  # 一直将self.num1作为输出的值
        else:
            raise StopIteration
    def __iter__(self):
        """迭代器的__iter__返回自身即可"""
        return self
if __name__ == '__main__':
    fib = FibIterator(10)
    for num in fib:
        print(num, end=" ")
```

###### 并不是只有for循环能接收可迭代对象

除了for循环能接收可迭代对象，list、tuple等也能接收。

```python
li = list(FibIterator(15))
print(li)
tp = tuple(FibIterator(6))
print(tp)
```

###### 小结

迭代器用极小的代码，极小的内存空间，生成数据

##### 生成器

利用迭代器，我们可以在每次迭代获取数据（通过next()方法）时按照特定的规律进行生成。但是我们在实现一个迭代器时，关于当前迭代到的状态需要我们自己记录，进而才能根据当前状态生成下一个数据。为了达到记录当前状态，并配合next()函数进行迭代使用，我们可以采用更简便的语法，即**生成器(generator)。生成器是一类特殊的迭代器**。 

###### 创建生成器方法1 - ()

把一个列表生成式的 [ ] 改成 ( )  —— 了解

```python
L = [x*2 for x in range(5)]
print(L)  # [0, 2, 4, 6, 8]
G = (x*2 for x in range(5))
print(G)  # <generator object <genexpr> at 0x00000196AB379308>
for i in G:
    print(i, end=" ")  # 0 2 4 6 8
```

创建 L 和 G 的区别仅在于最外层的 [ ] 和 ( ) ， L 是一个列表，而 G 是一个生成器。我们可以直接打印出列表L的每一个元素，而对于生成器G，我们可以按照迭代器的使用方法来使用，即可以通过next()函数、for循环、list()等方法使用。 

###### 创建生成器方法2 - 定义函数

```python
# 使用生成器完成 斐波那契数列
def fib(n):
    current = 0
    num1, num2 = 0, 1
    while current < n:
        num = num1
        num1, num2 = num2, num1+num2
        current += 1
        yield num
    return 'done'
F = fib(10)  # 只会将n取值为10，不会执行函数代码
for num in F:  # for循环时，开始执行函数，到yield语句时，返回内容（暂停而不是结束），再次循环时，从yield语句开始执行后续语句
    print(num)
```

在使用生成器实现的方式中，我们将原本在迭代器`__next__`方法中实现的基本逻辑放到一个函数中来实现，但是将每次迭代返回数值的return换成了yield，此时新定义的函数便不再是函数，而是一个**生成器（模板）**了。(理解为类)

简单来说：只要**在def中有yield关键字**的 就称为 **生成器**。

此时按照调用函数的方式使用生成器就不再是执行函数体了，而是会返回一个生成器对象，然后就可以按照使用迭代器的方式来使用生成器了。 

```python
def create_num(all_num):
    print("--1--", end=" ")
    a, b = 0, 1
    current_num = 0
    while current_num < all_num:
        print("--2--", end=" ")
        yield a  # 如果一个函数中有yield语句，那么这个就不在是函数，而是一个生成器的模板
        print("--3--", end=" ")
        a, b = b, a+b
        current_num += 1
        print("--4--", end=" ")
    return "done"
# 如果在调用create_num的时候，发现这个函数中有yield那么此时，不是调用函数，而是创建一个生成器对象
obj = create_num(10)
ret = next(obj)
print(ret, end=" ")
ret = next(obj)
print(ret, end=" ")
print("=" * 10)
obj2 = create_num(2)  # 创建第二个生成器对象
while True:  # 通过异常判断生成器已经结束
    try:
        ret = next(obj2)
        print(ret, end=" ")
    except StopIteration as ret:
        print(ret.value)
        # 读取 return 的值  想要得到生成器对象return结果，需要捕获异常，再通过value属性获取
        break
# --1-- --2-- 0 --3-- --4-- --2-- 1 ==========
# --1-- --2-- 0 --3-- --4-- --2-- 1 --3-- --4-- done
```

用for循环调用generator时，发现拿不到generator的return语句的返回值。如果想要拿到返回值，必须捕获StopIteration错误，返回值包含在StopIteration的value中 

###### 创建生成器方法3 - send()

 使用send()函数来唤醒执行。使用send()函数的一个好处是可以在唤醒的同时向断点处传入一个附加数据。 

```python
def create_num(all_num):
    a, b = 0, 1
    current_num = 0
    while current_num < all_num:
        ret = yield a
        print("ret>>>", ret, end=" ")
        a, b = b, a+b
        current_num += 1
obj = create_num(10)
# obj.send(None)  # send一般不会放到第一次启动生成器，如果非要这样做 那么传递None
ret = next(obj)
print(ret, end=" ")
ret = next(obj)
print(ret, end=" ")
# send里面的数据会 传递给第5行，当做yield a的结果，然后ret保存这个结果,,, 
# send的结果是下一次调用yield时 yield后面的值
ret = obj.send("hahahha")  
print(ret, end=" ")
# 0 ret>>> None 1 ret>>> hahahha 1 
```

可以使用send修改create_num中的参数，比如修改current_num的值，或者增加一些条件等

###### 小结

生成器：让函数暂停执行

- 使用了yield关键字的函数不再是函数，而是生成器。（使用了yield的函数就是生成器）
- yield关键字有两点作用：
  - 保存当前运行状态（断点），然后暂停执行，即将生成器（函数）挂起
  - 将yield关键字后面表达式的值作为返回值返回，此时可以理解为起到了return的作用
- 可以使用next()函数让生成器从断点处继续执行，即唤醒生成器（函数）
- Python3中的生成器可以使用return返回最终运行的返回值

##### 协程 - yield

协程，又称微线程，纤程。英文名Coroutine。 

协程是python个中另外一种实现多任务的方式，只不过比线程更小占用更小执行单元（理解为需要的资源）。 为啥说它是一个执行单元，因为它自带CPU上下文。这样只要在合适的时机， 我们可以把一个协程 切换到另一个协程。 只要这个过程中保存或恢复 CPU上下文那么程序还是可以运行的。

通俗的理解：在一个线程中的某个函数，可以在任何地方保存当前函数的一些临时变量等信息，然后切换到另外一个函数中执行，注意不是通过调用函数的方式做到的，并且切换的次数以及什么时候再切换到原来的函数都由开发者自己确定

```python
import time
def work1():
    while True:
        print("----work1---")
        yield
        time.sleep(0.5)
def work2():
    while True:
        print("----work2---")
        yield
        time.sleep(0.5)
def main():
    w1 = work1()
    w2 = work2()
    # 先让w1运行一会，当w1中遇到yield的时候，返回，然后
    # 执行w2，当它遇到yield的时候，再次切换到w1中
    # 这样w1/w2/w1/w2的交替运行，最终实现了多任务....协程
    while True:
        next(w1)
        next(w2)
if __name__ == "__main__":
    main()
# 假的多任务，并发的   一个进程中的一个线程
```

###### 协程和线程差异

在实现多任务时, 线程切换从系统层面远不止保存和恢复 CPU上下文这么简单。 操作系统为了程序运行的高效性每个线程都有自己缓存Cache等等数据，操作系统还会帮你做这些数据的恢复操作。 所以线程的切换非常耗性能。但是协程的切换只是单纯的操作CPU的上下文，所以一秒钟切换个上百万次系统都抗的住。

##### 协程 - greenlet

 为了更好使用协程来完成多任务，python中的greenlet模块对其封装，从而使得切换任务变的更加简单。

```python
from greenlet import greenlet
import time
def test1():
    while True:
        print("---A--")
        gr2.switch()
        time.sleep(0.5)
def test2():
    while True:
        print("---B--")
        gr1.switch()
        time.sleep(0.5)
gr1 = greenlet(test1)  # 返回值是 greenlet 对象
gr2 = greenlet(test2)
gr1.switch()  # 切换到gr1中运行
```

##### 协程 - gevent

greenlet已经实现了协程，但是还得人工切换，python还有一个比greenlet更强大的并且能够自动切换任务的模块`gevent` 

其原理是当一个greenlet遇到IO(指的是input output 输入输出，比如网络、文件操作等)操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。

由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO

###### gevent的使用

```python
import gevent
def f1(n):
    for i in range(n):
        print(gevent.getcurrent(), i)  #  gevent.getcurrent() 当前哪一个
        # time.sleep(0.5)  # 不可以，gevent不认为是耗时操作
        gevent.sleep(0.5)  # 模拟一个耗时操作 会自动切换
def f2(n):
    for i in range(n):
        print(gevent.getcurrent(), i)
        gevent.sleep(0.5)
def f3(n):
    for i in range(n):
        print(gevent.getcurrent(), i)
        gevent.sleep(0.5)
g1 = gevent.spawn(f1, 5)  # 参数一：去哪执行 二：参数  创建时不会执行
g2 = gevent.spawn(f2, 5)
g3 = gevent.spawn(f3, 5)
g1.join()  # 等待g1执行完  耗时操作，gevent自动开始切换
g2.join()
g3.join()
```

线程结束时协程死亡

`green.spawn`会启动所有协程，协程都是运行在同一个线程之中的，所以协程不能够跨线程同步数据。 

延时、堵塞等 都需要使用 gevent 中的，通过打补丁 自动实现

在Gevent中`gevent.sleep()`模拟的是Gevent可以识别的IO阻塞，若使用`time.sleep()`或其他阻塞，Gevent是不能够直接识别的，需要使用猴子补丁

###### 给程序打补丁

```python
from gevent import monkey  # 必须放在被打补丁的前面，如time、socket模块之前
import gevent
import random
import time

# 有耗时操作时需要
monkey.patch_all()  # 将程序中用到的耗时操作的代码，换为gevent中自己实现的模块

def coroutine_work(coroutine_name):
    for i in range(10):
        print(coroutine_name, i)
        time.sleep(random.random())

gevent.joinall([  # 等待所有，需要list
        gevent.spawn(coroutine_work, "work1"),
        gevent.spawn(coroutine_work, "work2")
])  # 等待所有协程执行完，才会结束
```

协程用 gevent，前两种都是原理。

##### 案例：图片下载器

实现：`gevent_img_downloader.py` 文件

##### 进程、线程、协程对比

请仔细理解如下的通俗描述：

- 有一个老板想要开个工厂进行生产某件商品（例如剪子）
- 他需要花一些财力物力制作一条生产线，这个生产线上有很多的器件以及材料这些所有的 为了能够生产剪子而准备的资源称之为：进程
- 只有生产线是不能够进行生产的，所以老板的找个工人来进行生产，这个工人能够利用这些材料最终一步步的将剪子做出来，这个来做事情的工人称之为：线程
- 这个老板为了提高生产率，想到3种办法：
  1. 在这条生产线上多招些工人，一起来做剪子，这样效率是成倍増长，即单进程 多线程方式
  2. 老板发现这条生产线上的工人不是越多越好，因为一条生产线的资源以及材料毕竟有限，所以老板又花了些财力物力购置了另外一条生产线，然后再招些工人这样效率又再一步提高了，即多进程 多线程方式
  3. 老板发现，现在已经有了很多条生产线，并且每条生产线上已经有很多工人了（即程序是多进程的，每个进程中又有多个线程），为了再次提高效率，老板想了个损招，规定：如果某个员工在上班时临时没事或者再等待某些条件（比如等待另一个工人生产完谋道工序 之后他才能再次工作） ，那么这个员工就利用这个时间去做其它的事情，那么也就是说：如果一个线程等待某些条件，可以充分利用这个时间去做其它事情，其实这就是：协程方式

简单总结

1. 进程是资源分配的单位
2. 线程是操作系统调度的单位
3. 进程切换需要的资源很最大，效率很低
4. 线程切换需要的资源一般，效率一般（当然了在不考虑GIL的情况下）
5. 协程切换任务资源很小，效率高
6. 多进程、多线程根据cpu核数不一样可能是并行的，但是协程是在一个线程中 所以是并发

### 2 Web 服务器

#### 正则表达式

判断是否符合条件//数据清洗，得到想要的数据

```python
import re  # 导入re模块
# 使用match方法进行匹配操作
result = re.match(正则表达式,要匹配的字符串)
# 如果上一步匹配到数据的话，可以使用group方法来提取数据
result.group()  # 满足要求的数据
```

```python
print(re.match(r"Chen", "ChenRong123"))  # 匹配出来陈
# run：<re.Match object; span=(0, 4), match='Chen'>
```

match：尝试从字符串的起始位置匹配一个模式，如果不是起始位置匹配成功的话，match()就返回none。 （匹配到会返回值,不然返回None）

##### 匹配单个字符

正则表达式的单字符匹配：

- `. `：匹配任意1个字符（除了\n）
- `[] `：匹配[ ]中列举的字符
- `\d `：匹配数字，即0-9
- `\D `：匹配非数字，即不是数字，大写字母都与小写相反
- `\s `：匹配空白，即 空格，tab键
- `\S `：匹配非空白
- `\w `：匹配单词字符，即a-z、A-Z、0-9、_ ，慎用，匹配中文等也可以
- `\W `：匹配非单词字符 

```python
import re
ret = re.match(r"t.o","two")
print(ret.group())
# 匹配0到9第一种写法
ret = re.match(r"[0123456789]Hello Python","7Hello Python")
print(ret.group())
# 匹配0到9第二种写法
ret = re.match(r"[0-9]Hello Python","7Hello Python")  # 连续的可以用 -
print(ret.group())
# 下面这个正则不能够匹配到数字4，因此ret为None
ret = re.match(r"[0-35-9]Hello Python","4Hello Python")
ret = re.match(r"[1-8a-c]Hello Python","aHello Python")  # 可以组合字母与数字
print(ret.group())
# 使用\d进行匹配
ret = re.match(r"嫦娥\d号","嫦娥1号发射成功") 
print(ret.group())
# 使用\w进行匹配
ret = re.match(r"\wHello Python","_Hello Python")
print(ret.group())
ret = re.match(r"\wHello Python","=Hello Python")
```

##### 匹配多个字符

匹配多个字符的相关格式，与其他配合

- `*`：匹配前一个字符出现0次或者无限次，即可有可无
- `+`：匹配前一个字符出现1次或者无限次，即至少有1次
- `?`：匹配前一个字符出现1次或者0次，即要么有1次，要么没有
- `{m}`：匹配前一个字符出现m次
- `{m,n}`：匹配前一个字符出现从m到n次

```python
import re
ret = re.match(r"\d{3,4}-?\d{8}","010-12345678")
print(ret.group())
html_content = """
sadad
caacd
23dcd
"""
ret = re.match(r".*",html_content)
print(ret.group())  # sadad
ret = re.match(r".*",html_content, re.S)  # re.S 使. 匹配 \n
print(ret.group())
# 匹配变量名是否有效
names = ["age", "_age", "1age", "age1", "a_age", "age_1_", "age!", "a#123", "__________"]
for name in names:
    # ^规定开头  $规定结尾  
    # python中的match默认是从头开始判断的所以，在match中可以不写^，
    # 但是match不会判断结尾，所以当需要以xxx结尾的时候 还需要写上$
    # ret = re.match(r"[A-Za-Z_]+[A-Za-Z_0-9]*", name) # 不需要+，这样就是一位
    ret = re.match(r"^[A-Za-Z_]+[A-Za-Z_0-9]*$", name)
    if ret:
        print("变量名:%s 符合要求....通过正则匹配出来的数据是:%s" % (name, ret.group()))
    else:
        print("变量名:%s 不符合要求...." % name)
```

##### 匹配开头结尾

- `^`：匹配字符串开头  （还有取反的含义）
- `$`：匹配字符串结尾

```python
# 匹配出163的邮箱地址，且@符号之前有4到20位英文、数字、下划线，例如hello@163.com
import re
email = input("请输入一个邮箱地址:")
# 如果在正则表达式中需要用到了某些普通的字符，比如 . 比如? 等，
# 仅仅需要在他们前面添加一个 反斜杠进行转义
ret = re.match(r"[a-zA-Z0-9_]{4,20}@163\.com$", email)
if ret:
	print("%s符合要求...." % email)
else:
	print("%s不符合要求...." % email)
```

##### 匹配分组

- `|`：匹配左右任意一个表达式
- `(ab)`：将括号中字符作为一个分组
- `\num`：引用分组num匹配到的字符串
- `(?P<name>)`：分组起别名
- `(?P=name)`：引用别名为name分组匹配到的字符串

```python
ret = re.match("[a-zA-Z0-9_]{4,20}@(163|126|qq)\.com$", "test@qq.com")
print(ret.group())  # test@qq.com
# () 还可以取数据 匹配成功后的
ret = re.match("([a-zA-Z0-9_]{4,20})@(163|126|qq)\.com$", "test@qq.com")
print(ret.group(1))  # test
print(ret.group(2))  # qq
# 使用 \num
ret = re.match(r"<([a-zA-Z]*)>\w*</\1>", "<html>hh</html>")  # \1 取分组中匹配的值
print(ret.group())
html_str = "<body><h1>hahahah</h1></body>"
ret = re.match(r"<(\w*)><(\w*)>.*</\2></\1>", html_str)
print(ret.group())
# 使用 (?P<name>)、(?P=name) 适用于分组很多时
ret = re.match(r"<(?P<p1>\w*)><(?P<p2>\w*)>.*</(?P=p2)></(?P=p1)>", html_str)
print(ret.group())
```

##### re 模块的高级用法

search： 扫描整个字符串并返回第一个成功的匹配。 

```python
import re
ret = re.search(r"\d+", "阅读次数为 9999")
print(ret.group())  # 9999
```

findall：在字符串中找到正则表达式所匹配的所有子串，并返回一个列表，如果没有找到匹配的，则返回空列表。

```python
import re
ret = re.findall(r"\d+", "python = 9999, c = 7890, c++ = 12345")
print(ret)  # ['9999', '7890', '12345']
```

sub：用于替换字符串中的匹配项 

```python
import re
ret = re.sub(r"\d+", '998', "python = 997, c++ = 1024")
print(ret)  # python = 998, c++ = 998
# sub 支持函数调用
def add(temp):
    strNum = temp.group()
    num = int(strNum) + 1
    return str(num)
ret = re.sub(r"\d+", add, "python = 99")
print(ret)  # python = 100
```

split：按照能够匹配的子串将字符串分割后返回列表

```python
import re
ret = re.split(r":| ","info:xiaoZhang 33 shandong")
print(ret)  # ['info', 'xiaoZhang', '33', 'shandong']
```

```python
import re
html_str = """
<dd class="job_bt">
        <h3 class="description">职位描述：</h3>
        <div>
        <p>职位诱惑：<br>机器学习相关项目，完全新技术驱动，互联网公司，工作氛围好，扁平管理，有技术大牛带<br><br>职位描述：<br>配合架构师和机器学习专家，完成项目的编码、测试和上线。<br><br>我们期望：<br>1.&nbsp;211院校计算机相关专业本科以上学历；<br>2.&nbsp;有扎实的编程和计算机基础，熟悉常用算法和数据结构。<br>3.&nbsp;具有很强的问题解决能力，综合知识（或者通过搜索能快速掌握知识）强，了解前端、网络、多线程、数据库、Web开发等知识。<br>4.&nbsp;2年以上工作经验（Python或者JAVA方向，如果编程能力特别过硬可以放开语言要求）；<br><br>工作内容：<br>1.&nbsp;根据业务需求进行需求分析和代码编写；<br>2.&nbsp;结合系统实现对代码进行充分的自测，以及配合测试工程师联合进行测试；<br>3.&nbsp;配合机器学习算法专家进行代码编写</p>
        </div>
    </dd>
"""
ret = re.findall(r"<[^>]*>", html_str)
# [^>]表示不是 > 的字符，*表示重复零次或更多次，这个意思是非 > 的字符可以有一个或多个，也可以没有。
# 意思就是不能有 > ,这 把 * 换为 + 一样  因为没有 <>这种
print(ret)
ret = re.sub(r"<[^>]*>|\s|&nbsp;", "", html_str)
print(ret)5
```

 当符号`^`在方括号表达式(`[]`)中使用时，表示**不接受该方括号表达式中的字符集合**。要匹配`^`字符本身，请使用 `\^`。 

##### 贪婪和非贪婪

Python里数量词默认是贪婪的，总是尝试匹配尽可能多的字符；非贪婪则相反，总是尝试匹配尽可能少的字符。在"*","?","+","{m,n}"后面加上？，使贪婪变成非贪婪。

```python
import re
s="This is a number 234-235-22-423"
r=re.match(r".+(\d+-\d+-\d+-\d+)",s)
print(r.group(1))  # '4-235-22-423'
r=re.match(r".+?(\d+-\d+-\d+-\d+)",s)
print(r.group(1))  # '234-235-22-423'
```

正则表达式模式中使用到通配字，那它在从左到右的顺序求值时，会尽量“抓取”满足匹配最长字符串，在我们上面的例子里面，“.+”会从字符串的启始处抓取满足模式的最长字符，其中包括我们想得到的第一个整型字段的中的大部分，“\d+”只需一位字符就可以匹配，所以它匹配了数字“4”，而“.+”则匹配了从字符串起始到这个第一位数字4之前的所有字符。

解决方式：非贪婪操作符“？”，这个操作符可以用在"*","+","?"的后面，要求正则匹配的越少越好。

```python
import re
ret = re.match(r"aa(\d+?)","aa2343ddd")
print(ret.group(1))  # '2'
ret = re.match(r"aa(\d+?)ddd","aa2343ddd")
print(ret.group(1))  # '2343'  由于限制了后边 非贪婪也是同样的结果
img_url = """<img data-original="https://rpic.douyucdn.cn/appCovers/2016/11/13/1213973_201611131917_small.jpg" src="https://rpic.douyucdn.cn/appCovers/2016/11/13/1213973_201611131917_small.jpg" style="display: inline;">"""
ret = re.search(r"https://.*?\.jpg", img_url)
print(ret.group())
```

##### r 的作用

 Python中字符串前面加上 r 表示原生字符串 

```python
import re
my_path = "c:\\a\\b\\c"
print(my_path)
print(re.match("c:\\\\a\\\\b\\\\c", my_path).group())
print(re.match(r"c:\\a\\b\\c", my_path).group())
```

>  正则表达式使用反斜杆（`\`）来转义特殊字符，使其可以匹配字符本身，而不是指定其他特殊的含义。这可能会和python字面意义上的字符串转义相冲突。比如，要匹配一个反斜杆本身，你也许要用`\\\\`来做为正则表达式的字符串，因为正则表达式要是`\\`，而字符串里，每个反斜杆都要写成`\\` 。
>
> 你也可以在字符串前加上 r 这个前缀来避免部分疑惑，因为 r 开头的python字符串是 raw 字符串，所以里面的所有字符都不会被转义，比如属`r'\n'`这个字符串就是一个反斜杆加上一字母n，而`'\n'`是个换行符。因此，上面的`'\\\\'`可以写成`r'\\'`，这样，应该就好理解很多了。

Python里的原生字符串很好地解决了这个问题，写出来的表达式也更直观。

#### HTTP 协议简介

在Web应用中，服务器把网页传给浏览器，实际上就是把网页的HTML代码发送给浏览器，让浏览器显示出来。而浏览器和服务器之间的传输协议是HTTP，所以：

- HTML是一种用来定义网页的文本，会HTML，就可以编写网页；
- HTTP是在网络上传输HTML的协议，用于浏览器和服务器的通信。

开发者工具中：Elements显示网页的结构、Network显示浏览器和服务器的通信

##### HTTP 协议的分析

发送或响应的数据是有格式的，这就是HTTP协议。（可用网络调试助手和浏览器模拟请求与响应）

##### 浏览器请求

最主要的头两行分析如下，第一行：`GET / HTTP/1.1`

GET表示一个读取请求，将从服务器获得网页数据（要），/表示URL的路径，URL总是以/开头，/就表示首页，最后的HTTP/1.1指示采用的HTTP协议版本是1.1。目前HTTP协议的版本就是1.1，但是大部分服务器也支持1.0版本，主要区别在于1.1版本允许多个HTTP请求复用一个TCP连接(长连接)，以加快传输速度。

从第二行开始，每一行都类似于Xxx: abcdefg（为字符串），如`Host: www.sina.com`，表示请求的域名是`www.sina.com`。如果一台服务器有多个网站，服务器就需要通过Host来区分浏览器请求的是哪个网站。

 **HTTP协议里，一个Header一行** 

> 长连接；接受的格式；浏览器版本；接受的压缩格式；接受的语言 等等

**发送的Header是告诉服务器怎么做/要求**

发送的请求格式如下：

```http
GET / HTTP/1.1
Host: www.baidu.com
Connection: keep-alive
Cache-Control: max-age=0
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36
Accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3
Accept-Encoding: gzip, deflate, br
Accept-Language: zh-CN,zh;q=0.9
```

HTTP请求分为Header和Body两部分。POST 时 会有 Body。

##### 服务器响应

HTTP响应分为Header和Body两部分（Body是可选项），我们在Network中看到的Header最重要的几行如下：

`HTTP/1.1 200 OK` ：200表示一个成功的响应，后面的OK是说明。如果返回的不是200，那么往往有其他的功能，例如：失败的响应有404 Not Found：网页不存在；500 Internal Server Error：服务器内部出错；等等。

`Content-Type: text/html`：Content-Type指示响应的内容，这里是text/html表示HTML网页。

> 请注意，浏览器就是依靠Content-Type来判断响应的内容是网页还是图片，是视频还是音乐。浏览器并不靠URL来判断响应的内容，所以，即使URL是`http://www.baidu.com/meimei.jpg`，它也不一定就是图片。

**响应的Header是告诉浏览器怎么做/要求**

响应的数据格式如下：

```http
HTTP/1.1 200 OK
Bdpagetype: 2
Bdqid: 0xced4a9a1000734e4
Cache-Control: private
Connection: keep-alive
Content-Encoding: gzip
Content-Type: text/html;charset=utf-8
Date: Tue, 14 Apr 2020 09:38:07 GMT
Expires: Tue, 14 Apr 2020 09:38:06 GMT
Server: BWS/1.1
Set-Cookie: BDSVRTM=316; path=/
Set-Cookie: BD_HOME=1; path=/
Set-Cookie: H_PS_PSSID=1461_31125_21111_31187_30908_30823_31085_31164_31196; path=/; domain=.baidu.com
Strict-Transport-Security: max-age=172800
Traceid: 1586857087060169268214903723575831114980
X-Ua-Compatible: IE=Edge,chrome=1
Transfer-Encoding: chunked

<!DOCTYPE html>
等等
```

HTTP响应的Body就是HTML源码，选择查看网页源码可以在浏览器中直接查看HTML源码。

Header是连续的，没有空行，只要有空行，则后边内容为Body。HTTP 中的换行使用：`\r\n`

##### 浏览器解析过程

当浏览器读取到新浪首页的HTML源码后，它会解析HTML，显示页面，然后，根据HTML里面的各种链接，再发送HTTP请求给新浪服务器，拿到相应的图片、视频、Flash、JavaScript脚本、CSS等各种资源，最终显示出一个完整的页面。所以我们在Network下面能看到很多额外的HTTP请求。

##### HTTP 小结

###### HTTP 请求与响应

步骤1：浏览器首先向服务器发送HTTP请求，请求包括：

> **方法**：GET还是POST，GET仅请求资源，POST会附带用户数据；**路径**：/full/url/path；**域名**：由Host头指定：`Host: www.sina.com`；以及其他相关的Header；
>
> 如果是POST，那么请求还包括一个Body，包含用户数据

步骤2：服务器向浏览器返回HTTP响应，响应包括：

> **响应代码**：200表示成功，3xx表示重定向，4xx表示客户端发送的请求有错误，5xx表示服务器端处理时发生了错误；**响应类型**：由Content-Type指定；以及其他相关的Header；
>
> 通常服务器的HTTP响应会携带内容，也就是有一个Body，包含响应的内容，网页的HTML源码就在Body中。

步骤3：如果浏览器还需要继续向服务器请求其他资源，比如图片，就再次发出HTTP请求，重复步骤1、2。

> Web采用的HTTP协议采用了非常简单的请求-响应模式，从而大大简化了开发。当我们编写一个页面时，我们只需要在HTTP请求中把HTML发送出去，不需要考虑如何附带图片、视频等，浏览器如果需要请求图片和视频，它会发送另一个HTTP请求，因此，**一个HTTP请求只处理一个资源(此时就可以理解为TCP协议中的短连接，每个链接只获取一个资源，如需要多个就需要建立多个连接)**

HTTP协议同时具备极强的扩展性，虽然浏览器请求的是`http://www.sina.com`的首页，但是新浪在HTML中可以链入其他服务器的资源，比如`<img src="http://i1.sinaimg.cn/home/2013/1008/U8455P30DT20131008135420.png">  `，从而将请求压力分散到各个服务器上，并且，一个站点可以链接到其他站点，无数个站点互相链接起来，就形成了World Wide Web，简称WWW。

###### HTTP 格式

每个HTTP请求和响应都遵循相同的格式，一个HTTP包含Header和Body两部分，其中Body是可选的。HTTP协议是一种文本协议，所以，它的格式也非常简单。

**HTTP GET请求的格式：**

```http
GET /path HTTP/1.1
Header1: Value1
Header2: Value2
Header3: Value3
```

**每个Header一行一个，换行符是`\r\n`。**

**HTTP POST请求的格式：**

```http
POST /path HTTP/1.1
Header1: Value1
Header2: Value2
Header3: Value3

body data goes here...
```

**当遇到连续两个`\r\n`时，Header部分结束，后面的数据全部是Body。**

**HTTP响应的格式：**

````http
200 OK
Header1: Value1
Header2: Value2
Header3: Value3

body data goes here...
```

HTTP响应如果包含body，也是通过**两个`\r\n`来分隔**的。

Body的数据类型由Content-Type头来确定，如果是网页，Body就是文本，如果是图片，Body就是图片的二进制数据。

当存在Content-Encoding时，Body数据是被压缩的，最常见的压缩方式是gzip，所以，看到Content-Encoding: gzip时，需要将Body数据先解压缩，才能得到真正的数据。压缩的目的在于减少Body的大小，加快网络传输。

#### Web静态服务器

##### Web静态服务器-1-显示固定的页面

python 实现服务器，浏览器请求

```python
# show_a_html.py
import socket
def service_client(new_socket):
    """为这个客户端返回数据"""
    # 1. 接收浏览器发送过来的请求 ，即http请求  
    # GET / HTTP/1.1
    # .....
    request = new_socket.recv(1024)
    print(request)
    # 2. 返回http格式的数据，给浏览器
    # 2.1 准备发送给浏览器的数据---header
    response = "HTTP/1.1 200 OK\r\n"
    response += "\r\n"  # 浏览器解析换行 用\r\n
    # 2.2 准备发送给浏览器的数据---body
    response += "hahahhah"
    new_socket.send(response.encode("utf-8"))
    new_socket.close()  # 关闭套接字 !
def main():
    """用来完成整体的控制"""
    tcp_server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)  # 1. 创建套接字
    tcp_server_socket.bind(("", 7890))  # 2. 绑定
    tcp_server_socket.listen(128)  # 3. 变为监听套接字
    while True:
        new_socket, client_addr = tcp_server_socket.accept()  # 4. 等待新客户端的链接
        service_client(new_socket)  # 5. 为这个客户端服务
    tcp_server_socket.close()  # 关闭监听套接字 !
if __name__ == "__main__":
    main()
```

##### TCP 的`3`次握手

<img src="https://user-images.githubusercontent.com/51505633/79301086-28963a80-7f1b-11ea-81e8-874a05acc295.png" alt="三次握手、四次挥手" style="zoom:67%;" />

# TCP 的`4`次挥手



3次握手的开始是 connect发起，成功是服务器调用 accept



4次原因



服务器 超时时间

客户端 等2分多 防止 服务器没收到应答，再次发送

 2 MSL

谁先调 close  谁等待

客户端端口随机

# Web静态服务器-2-显示需要的页面

```python
# show_need_html.py
import socket
import re
import os
def service_client(new_socket):
    """为这个客户端返回数据"""
    # 1. 接收浏览器发送过来的请求 ，即http请求  
    # GET / HTTP/1.1
    # .....
    request = new_socket.recv(1024).decode("utf-8")
    print(">>>"*50)
    print(request)
    request_lines = request.splitlines()  # 先切割
    print("")
    print(">"*20)
    print(request_lines)
    # GET /index.html HTTP/1.1
    # get post put del
    file_name = ""
    ret = re.match(r"[^/]+(/[^ ]*)", request_lines[0]) # 不是/都行  空格停
    if ret:
        file_name = ret.group(1)
        print("*"*50, file_name)
        if file_name == "/":  # 这需要上面的变量
            file_name = "/index.html"
        file_name = file_name[1:]  # 和linux 不同，路径不一致 这用替换更好
    # 2. 返回http格式的数据，给浏览器
    file_path = os.path.join(".\html", file_name)
    print("file_path >>> ", file_path)
    try:
        f = open(file_path, "rb")  # 打开文件有危险
    except:
        response = "HTTP/1.1 404 NOT FOUND\r\n"
        response += "\r\n"
        response += "------file not found-----"
        new_socket.send(response.encode("utf-8"))
    else:
        html_content = f.read()
        f.close()
        # 2.1 准备发送给浏览器的数据---header
        response_header = "HTTP/1.1 200 OK\r\n"
        response_header += "\r\n"
        # 2.2 准备发送给浏览器的数据---boy
        response_body = html_content
        response = response_header.encode("utf-8") + response_body
        # 将response发送给浏览器
        new_socket.send(response)
        # 将response body发送给浏览器
        # new_socket.send(html_content)
    # 关闭套接字
    new_socket.close()
def main():
    """用来完成整体的控制"""
    # 1. 创建套接字
    tcp_server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)  # 1. 创建套接字
    # 设置当服务器先close 即服务器端4次挥手之后资源能够立即释放
    # 这样就保证了，下次运行程序时 可以立即绑定7890端口
    tcp_server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    # 2. 绑定
    tcp_server_socket.bind(("127.0.0.1", 7899))
    # 3. 变为监听套接字
    tcp_server_socket.listen(128)
    while True:
        # 4. 等待新客户端的链接
        new_socket, client_addr = tcp_server_socket.accept()
        # 5. 为这个客户端服务
        service_client(new_socket)
    # 关闭监听套接字
    tcp_server_socket.close()
if __name__ == "__main__":
    main()
```

以上代码需要 html 文件夹

存在问题：有时候 request 返回空值，会报错！当客户端的套接字调用close后，服务器端会recv解堵塞，并且返回的长度为0，因此服务器可以通过返回数据的长度来区别客户端是否已经下线?

```python
server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
# 设置当服务器先close 即服务器端4次挥手之后资源能够立即释放，这样就保证了
# 下次运行程序时 可以立即绑定7788端口
```

##### Web静态服务器-3-多进程

需要在主进程调用new_socket.close()，未修改文件目录

```python
import socket
import re
import multiprocessing
def service_client(new_socket):
    """为这个客户端返回数据"""
    request = new_socket.recv(1024).decode("utf-8")
    request_lines = request.splitlines()
    file_name = ""
    ret = re.match(r"[^/]+(/[^ ]*)", request_lines[0])
    if ret:
        file_name = ret.group(1)
        if file_name == "/":
            file_name = "/index.html"
    try:
        f = open("./html" + file_name, "rb")
    except:
        response = "HTTP/1.1 404 NOT FOUND\r\n"
        response += "\r\n"
        response += "------file not found-----"
        new_socket.send(response.encode("utf-8"))
    else:
        html_content = f.read()
        f.close()
        response = "HTTP/1.1 200 OK\r\n"
        response += "\r\n"
        new_socket.send(response.encode("utf-8"))
        new_socket.send(html_content)
    # 关闭套接字
    new_socket.close()
def main():
    """用来完成整体的控制"""
    tcp_server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    tcp_server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    tcp_server_socket.bind(("", 7890))
    tcp_server_socket.listen(128)
    while True:
        new_socket, client_addr = tcp_server_socket.accept()
        # 5. 为这个客户端服务
        p = multiprocessing.Process(target=service_client, args=(new_socket,))
        p.start()
        new_socket.close()  # 子进程复制了new_socket，关闭的是子进程的，主进程还需要关闭
        # 主进程不调用close时, 浏览器会一直的等待, 四次挥手就不会开始!
        # 两个 new_socket 指向的同一个文件 类似于
    # 关闭监听套接字
    tcp_server_socket.close()
if __name__ == "__main__":
    main()
```

##### Web静态服务器-4-多线程

无需在主线程调用new_socket.close()，未修改文件目录

```python
import socket
import re
import threading
def service_client(new_socket):
    """为这个客户端返回数据"""
    request = new_socket.recv(1024).decode("utf-8")
    request_lines = request.splitlines()
    file_name = ""
    ret = re.match(r"[^/]+(/[^ ]*)", request_lines[0])
    if ret:
        file_name = ret.group(1)
        if file_name == "/":
            file_name = "/index.html"
    try:
        f = open("./html" + file_name, "rb")
    except:
        response = "HTTP/1.1 404 NOT FOUND\r\n"
        response += "\r\n"
        response += "------file not found-----"
        new_socket.send(response.encode("utf-8"))
    else:
        html_content = f.read()
        f.close()
        response = "HTTP/1.1 200 OK\r\n"
        response += "\r\n"
        new_socket.send(response.encode("utf-8"))
        new_socket.send(html_content)
    # 关闭套接字
    new_socket.close()
def main():
    """用来完成整体的控制"""
    tcp_server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    tcp_server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    tcp_server_socket.bind(("", 7890))
    tcp_server_socket.listen(128)
    while True:
        new_socket, client_addr = tcp_server_socket.accept()
        # 5. 为这个客户端服务
        p = threading.Thread(target=service_client, args=(new_socket,))
        p.start()
        # new_socket.close() 多线程没有复制,共享，不需要close
    # 关闭监听套接字
    tcp_server_socket.close()
if __name__ == "__main__":
    main()
```

区别: 线程比线程耗费的资源小, 以下用协程实现, 会更方便 

多进程、多线程 在请求量的大时消耗资源过大

##### Web静态服务器-5-协程

使用gevent实现http服务器，效率最高

```python
from gevent import monkey
import socket
import re
import gevent
monkey.patch_all()
def service_client(new_socket):
    """为这个客户端返回数据"""
    request = new_socket.recv(1024).decode("utf-8")
    request_lines = request.splitlines()
    file_name = ""
    ret = re.match(r"[^/]+(/[^ ]*)", request_lines[0])
    if ret:
        file_name = ret.group(1)
        if file_name == "/":
            file_name = "/index.html"
    try:
        f = open("./html" + file_name, "rb")
    except:
        response = "HTTP/1.1 404 NOT FOUND\r\n"
        response += "\r\n"
        response += "------file not found-----"
        new_socket.send(response.encode("utf-8"))
    else:
        html_content = f.read()
        f.close()
        response = "HTTP/1.1 200 OK\r\n"
        response += "\r\n"
        new_socket.send(response.encode("utf-8"))
        new_socket.send(html_content)
    # 关闭套接
    new_socket.close()
def main():
    """用来完成整体的控制"""
    tcp_server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    tcp_server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    tcp_server_socket.bind(("", 7890))
    tcp_server_socket.listen(128)
    while True:
        new_socket, client_addr = tcp_server_socket.accept()
        # 5. 为这个客户端服务
        gevent.spawn(service_client, new_socket)
        # new_socket.close()
    # 关闭监听套接字
    tcp_server_socket.close()
if __name__ == "__main__":
    main()
```

 `green.spawn`会启动所有协程，协程都是运行在同一个线程之中的，所以协程不能够跨线程同步数据。 

原来的`join()` 和` joinall()` 都是为了阻塞当前流程，并执行所有给定的Greenlet，执行流只会在所有的Greenlet执行完毕后才会继续向下执行。 

而现在是无限循环，因此不需要`join()` 和` joinall()` 

##### Web静态服务器-6-单进程-单线程-非堵塞模式

单进程-单线程 时 会在 recv() 堵塞， accept无法服务，因此要实现 单进程-单线程 时 不堵塞

由于套接字默认堵塞，可用如下命令设置套接字为非堵塞的方式

`tcp_server_tcp.setblocking(False)  # 设置套接字为非堵塞的方式`

非堵塞时，accept() 、recv()数据没来 会产生异常，需要异常处理

```python
import socket
import time
tcp_server_tcp = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
tcp_server_tcp.bind(("", 7899))
tcp_server_tcp.listen(128)
tcp_server_tcp.setblocking(False)  # 设置套接字为非堵塞的方式
# while True:
#     try:
#         new_socket, new_addr = tcp_server_tcp.accept()
#     except Exception as ret:
#         print("---没有新的客户端到来---")
#     else:
#         print("---只要没有产生异常，那么也就意味着 来了一个新的客户端----")
#         new_socket.setblocking(False)  # 设置套接字为非堵塞的方式 因为默认堵塞
#         try:
#             recv_data = new_socket.recv(1024)
#            except Exception as ret:
#                 print(ret)
#                 print("----这个客户端没有发送过来数据----")
#             else:
#                 print("-----没有异常,客户端发送过来数据-----")
#                 print(recv_data)
# 上面存在问题 有一个客户端到来时 但没有数据，再次while时 就变为等新客户端到来
# 把 第二个 try 移出去， 使用list 保存 请求的客户端
# client_socket_list.append(new_socket)
client_socket_list = list()
while True:
    time.sleep(0.5)
    try:
        new_socket, new_addr = tcp_server_tcp.accept()
    except Exception as ret:
        print("---没有新的客户端到来---")
    else:
        print("---只要没有产生异常，那么也就意味着 来了一个新的客户端----")
        new_socket.setblocking(False)  # 设置套接字为非堵塞的方式
        client_socket_list.append(new_socket)
    for client_socket in client_socket_list:
        try:
            recv_data = client_socket.recv(1024)  # 对方调用close后 删除套接字
        except Exception as ret:
            print(ret)
            print("----这个客户端没有发送过来数据----")
        else:
            print("-----没有异常-----")
            print(recv_data)
            if recv_data:
                # 对方发送过来数据
                print("----客户端发送过来了数据-----")
            else:
                # 对方调用close 导致了 recv返回
                client_socket.close()  # 这都是引用 执行顺序可以换
                client_socket_list.remove(client_socket)
                print("---客户端已经关闭----")
```

上述代码实现了单进程-单线程，监听多个套接字

普通的方式，单进程-单线程会堵塞，导致多浏览器访问时等待，所以使用多线程、多进程为其服务；上边代码是单进程-单线程，通过非阻塞监听多个套接字，实现了同样的目的。

因为列表的循环执行的，所以是并发服务器。

系统先收数据，有个缓存区，recv 时取走数据(0.5 秒检查，短时间到达缓存区的，会一起取走)，没有则产生异常/堵塞。

##### 长连接、短连接

TCP在真正的读写操作之前，server与client之间必须建立一个连接，当读写操作完成后，双方不再需要这个连接时它们可以释放这个连接，连接的建立通过三次握手，释放则需要四次握手，所以说每个连接的建立都是需要资源消耗和时间消耗的。

###### TCP短连接

模拟一种TCP短连接的情况:

1. client 向 server 发起连接请求
2. server 接到请求，双方建立连接
3. client 向 server 发送消息
4. server 回应 client
5. 一次读写完成，此时双方任何一个都可以发起 close 操作

在步骤5中，一般都是 client 先发起 close 操作。当然也不排除有特殊的情况。从上面的描述看，短连接一般只会在 client/server 间传递一次读写操作！

###### TCP长连接

再模拟一种长连接的情况:

1. client 向 server 发起连接
2. server 接到请求，双方建立连接
3. client 向 server 发送消息
4. server 回应 client
5. 一次读写完成，连接不关闭
6. 后续读写操作...
7. 长时间操作之后client发起关闭请求

###### TCP长/短连接操作过程

- 短连接的操作步骤是：建立连接——数据传输——关闭连接...建立连接——数据传输——关闭连接
- 长连接的操作步骤是：建立连接——数据传输...（保持连接）...数据传输——关闭连接

###### TCP长/短连接的优点和缺点

- **长连接**可以**省**较多的**TCP建立和关闭**的操作，减少浪费，节约时间。对于**频繁请求资源**的客户来说，较**适用长连接**。
- client与server之间的连接如果一直不关闭的话，会存在一个问题，随着客户端连接越来越多，server早晚有扛不住的时候，这时候server端需要采取一些策略，如关闭一些长时间没有读写事件发生的连接，这样可以避免一些恶意连接导致server端服务受损；如果条件再允许就可以以客户端机器为颗粒度，限制每个客户端的最大长连接数，这样可以完全避免某个蛋疼的客户端连累后端服务。
- **短连接**对于服务器来说**管理较为简单**，存在的连接都是有用的连接，**不需要额外的控制手段**。但**如果客户请求频繁**，将在**TCP的建立和关闭操作上浪费时间和带宽**。

###### TCP长/短连接的应用场景

-  长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况。 例如：数据库的连接用长连接，如果用短连接频繁的通信会造成socket错误，而且频繁的socket 创建也是对资源的浪费。
-  像WEB网站的http服务一般都用短链接，因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源。

**HTTP/1.1 -- 长连接    HTTP/1.0 -- 短连接**

网页图片多时，需要都从服务器获取，短连接方式，服务器需要多个进程/线程 处理，浪费资源；长连接时不会再建立新的 进程/线程/协程

##### Web静态服务器-6-单进程-单线程-非堵塞-长连接模式

上面实现的代码都是短连接，因为虽然用的 HTTP/1.1，但是服务器返回数据后，关闭套接字，断开连接了。

```python
import socket
import re
def service_client(new_socket, request):
    """为这个客户端返回数据"""
    request_lines = request.splitlines()
    file_name = ""
    ret = re.match(r"[^/]+(/[^ ]*)", request_lines[0])
    if ret:
        file_name = ret.group(1)
        if file_name == "/":
            file_name = "/index.html"
    try:
        f = open("./html" + file_name, "rb")
    except:
        response = "HTTP/1.1 404 NOT FOUND\r\n"
        response += "\r\n"
        response += "------file not found-----"
        new_socket.send(response.encode("utf-8"))
    else:
        html_content = f.read()
        f.close()
        response_body = html_content
        response_header = "HTTP/1.1 200 OK\r\n"
        response_header += "Content-Length:%d\r\n" % len(response_body)
        # Content-Length:len-->浏览器此时不需要调用close会自动发起新请求
        response_header += "\r\n"
        response = response_header.encode("utf-8") + response_body  # 此时都是二进制字符串
        new_socket.send(response)
        # 这不能 close()，那如何使浏览器知道数据已经收完了？
        # Content-Length 告诉浏览器body长度，浏览器获取完所需全部数据后，主动断开连接
def main():
    """用来完成整体的控制"""
    tcp_server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    tcp_server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    tcp_server_socket.bind(("", 7890))
    tcp_server_socket.listen(128)
    tcp_server_socket.setblocking(False)  # 将套接字变为非堵塞
    client_socket_list = list()
    while True:
        try:  # 等待新客户端的链接
            new_socket, client_addr = tcp_server_socket.accept()
        except Exception as ret:
            pass
        else:
            new_socket.setblocking(False)
            client_socket_list.append(new_socket)
        for client_socket in client_socket_list:
            try:
                recv_data = client_socket.recv(1024).decode("utf-8")
            except Exception as ret:
                pass
            else:
                if recv_data:
                    service_client(client_socket, recv_data)  # 将数据传入
                else:
                    client_socket.close()  # 浏览器获取完所需全部数据后，主动 close() (挥手)
                    client_socket_list.remove(client_socket)
    # 关闭监听套接字
    tcp_server_socket.close()
if __name__ == "__main__":
    main()
```

##### Web静态服务器-7-epoll

epoll —— linux服务器采用，nginx 采用 epoll 实现

epoll 是单进程单线程，epoll 将列表放入特殊内存空间，应用和内核都可访问，没有拷贝过程，套接字的文件描述符检测时不遍历(轮询)，通过事件通知方式

事件通知：哪个套接字数据到了，通知套接字收

特点：**共享内存**、**事件通知**

```python
# epoll 实现 HTTP 服务器
import socket
import re
import select
def service_client(new_socket, request):
    """为这个客户端返回数据"""
    request_lines = request.splitlines()
    file_name = ""
    ret = re.match(r"[^/]+(/[^ ]*)", request_lines[0])
    if ret:
        file_name = ret.group(1)
        # print("*"*50, file_name)
        if file_name == "/":
            file_name = "/index.html"
    try:
        f = open("./html" + file_name, "rb")
    except:
        response = "HTTP/1.1 404 NOT FOUND\r\n"
        response += "\r\n"
        response += "------file not found-----"
        new_socket.send(response.encode("utf-8"))
    else:
        html_content = f.read()
        f.close()
        response_body = html_content
        response_header = "HTTP/1.1 200 OK\r\n"
        response_header += "Content-Length:%d\r\n" % len(response_body)
        response_header += "\r\n"
        response = response_header.encode("utf-8") + response_body
        new_socket.send(response)
def main():
    """用来完成整体的控制"""
    tcp_server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    tcp_server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    tcp_server_socket.bind(("", 7890))
    tcp_server_socket.listen(128)
    tcp_server_socket.setblocking(False)  # 将套接字变为非堵塞
    # 创建一个epoll对象
    epl = select.epoll()
    # 将监听套接字对应的fd注册到epoll中
    epl.register(tcp_server_socket.fileno(), select.EPOLLIN)
    # tcp_server_socket.fileno() 获取对应文件描述符(fd)，其为数字
    # select.EPOLLIN 监测前一个是否有输入，事件类型
    fd_event_dict = dict()
    while True:
        fd_event_list = epl.poll()  # 返回列表
        # 默认会堵塞，直到 os监测到数据到来 通过事件通知方式 告诉这个程序，此时才会解堵塞
        # [(fd, event), (套接字对应的文件描述符, 这个文件描述符到底是什么事件 例如 可以调用recv接收等)]
        for fd, event in fd_event_list:
            # 等待新客户端的链接
            if fd == tcp_server_socket.fileno():  # 第一次肯定为 tcp_server_socket
                new_socket, client_addr = tcp_server_socket.accept()
                epl.register(new_socket.fileno(), select.EPOLLIN)  # 将套接字对应的fd注册到epoll中
                fd_event_dict[new_socket.fileno()] = new_socket  # 为了根据 fd 得到 socket
            elif event==select.EPOLLIN:
                # 判断已经链接的客户端是否有数据发送过来
                recv_data = fd_event_dict[fd].recv(1024).decode("utf-8")
                if recv_data:
                    service_client(fd_event_dict[fd], recv_data)
                else:
                    fd_event_dict[fd].close()
                    epl.unregister(fd)
                    del fd_event_dict[fd]
    # 关闭监听套接字
    tcp_server_socket.close()
if __name__ == "__main__":
    main()
```

### 3 网络通信

#### TCP/IP协议(族)

协议就是一个规定。为了把全世界的所有不同类型的计算机都连接起来，就必须规定一套全球通用的协议，为了实现互联网这个目标，互联网协议族（Internet Protocol Suite）就是通用协议标准。因为互联网协议包含了上百种协议标准，但是最重要的两个协议是TCP和IP协议，所以，大家把互联网的协议**简称TCP/IP协议(族)**

常用的网络协议如下图所示：

![TCP-IP协议族中各协议之间的关系](https://user-images.githubusercontent.com/51505633/79482359-52e31780-8043-11ea-8e29-bb207c9e9152.jpg)

![传输示意图](https://github.com/sunhx0914/Picture/issues/2#issuecomment-614763369)

传输层添加端口，IP层添加ip，链路层帧头为mac地址(网卡上的序列号)

事实标准：应用层、运输层、网际层(网络层)、网络接口层(链路层)  —— TCP/IP 四层模型

理论标准：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层  —— OSI 七层模型

#### wireshark

过滤条件：tcp、ip.src、ip.dst、udp.port == 2405、ip.src == 192.168.33.45 and(or) udp

目的：确定数据发送成功与否、判断哪出问题

#### 网络通信过程

##### 2台电脑的网络

如果两台电脑之间通过网线连接是可以直接通信的，但是需要提前设置好ip地址以及网络掩码，并且ip地址需要控制在同一网段内， 例如 一台为`192.168.1.1`另一台为`192.168.1.2` 

ip地址 用于区分主机

网络掩码 与 ip地址 按位与操作(都1时为1) ，计算主机号和网络号，确定是否为同一网络

##### 使用集线器组成一个网络

当有多台电脑需要组成一个网时，那么可以通过集线器（Hub）将其链接在一起。一般集线器的接口较少

网线中是电信号 不能像电线一样多接

集线器缺点：它以**广播**的方式进行发送任何数据，即如果集线器接收到来自A电脑的数据本来是想转发给B电脑，如果此时它还连接着另外两台电脑C、D，那么它会把这个数据给每个电脑都发送一份，因此会导致网络拥堵

##### 使用交换机组成一个网络

克服了集线器以广播发送数据的缺点，当需要广播的时候发送广播，当需要单播的时候又能够以单播的方式进行发送，它已经替代了之前的集线器。

网卡要先判断是否发给自己，因此需要mac地址(可通过arp协议获取）

arp 广播得到目的 ip 对应的 mac地址

网卡默认接收 FF:FF:FF:FF:FF:FF 的地址，通过这个返回目的mac地址

发送数据(去)时是广播，返回数据(回)时不是广播，因为已经知道了源ip和源mac

##### 使用路由器连接多个网络

路由器： 连接不同的网络

为了让自己电脑能发送数据给不同的网络号里电脑， 必须要设置默认网关

默认网关是能转发数据的设备，往往是路由器

发给默认网关时，mac地址写的是默认网关的mac地址， 转发的时候写的是默认网关的另一个mac地址，ip地址不变

路由器转发数据时，ip地址保持不变，源、目的mac一直在变

<img width="1514" alt="QQ20171023-111517@2x" src="https://user-images.githubusercontent.com/51505633/79484902-fa157e00-8046-11ea-897e-781bfe3ea0b6.png">

##### 通信过程(复杂)

较为复杂的通信过程如：访问`www.itheima.com `

1. 在浏览器中输入一个网址时，需要将它先**解析出ip地址**来(DNS服务器用来解析域名对应的ip地址)

   本地有DNS服务器 ip 地址

   通过arp得到默认网关地址，将请求的域名解析数据发送给网关，网关接入互联网，层层转发，DNS服务器接收到数据后，返回域名对应的ip地址

   ip地址是由范围的，通过ip可以知道地区

2. 当得到ip地址之后，浏览器以tcp的方式3次握手连接服务器

3. 以tcp的方式发送http协议的请求数据 给 服务器

4. 服务器tcp的方式回应http协议的应答数据 给浏览器，浏览器显示数据

5. 浏览器发送tcp的4次挥手

路由器之间有发现协议

<img width="1092" alt="QQ20170807-212411@2x" src="https://user-images.githubusercontent.com/51505633/79487291-9bea9a00-804a-11ea-8972-8a6c399b84de.png">

#### NAT(网络地址转换器)

1. 当在家里用宽带链接上网时，会把电话线(光纤)---->调制解调制(简称猫)------->电脑等设备

2. 电脑会得到来自电信服务商的一个公网ip地址（**只有公网ip地址才能上网**），此时可以直接上网

3. 为了能够让多台设备都可以上网，需要将数据进行“分流” 电话线(光纤)---->调制解调制(简称猫)------->路由器------>电脑等设备

4. 此时路由器的一端有一个公网ip地址，剩下的4个（型号不同个数不同）可以接入电脑等设备 并且 它们的ip是私有ip(例如 192.168.1.2)

5. 当一个电脑（192.168.1.2）上网时，先通过DNS协议解析出某个域名对应的ip，然后

   - 发送数据时,在经过路由器时转换为公网ip以及路由器自己分配的临时端口

     192.168.1.2:6789----->192.168.1.1 路由器 116.226.52.212:6539------->猫---->万维网

   - 接收数据时,在经过路由器时转换为路由器之前记录的ip以及port

     万维网------->猫----->116.226.52.212:6539 路由器 192.168.1.1 ---->192.168.1.2:6789

<img width="1184" alt="QQ20171023-123017@2x" src="https://user-images.githubusercontent.com/51505633/79487880-7f029680-804b-11ea-8a3d-62aa2c1c3b73.png" style="zoom: 45%;" >

#### 总结

- MAC地址：在设备与设备之间数据通信时用来标记收发双方（网卡的序列号）
- IP地址：在逻辑上标记一台电脑，用来指引数据包的收发方向（相当于电脑的序列号）
- 网络掩码：用来区分ip地址的网络号和主机号
- 默认网关：当需要发送的数据包的目的ip不在本网段内时，就会发送给默认的一台电脑，成为网关
- 集线器：已过时，用来连接多态电脑，缺点：每次收发数据都进行广播，网络会变的拥堵
- 交换机：集线器的升级版，有学习功能知道需要发送给哪台设备，根据需要进行单播、广播
- 路由器：连接多个不同的网段，让他们之间可以进行收发数据，每次收到数据后，ip不变，但是MAC地址会变化
- DNS：用来解析出IP（类似电话簿）
- http服务器：提供浏览器能够访问到的数据







**通信过程：**

1 DNS 解析 域名    有 DNS 的ip，，得先发送给网关，，得先发 arp 得到 网关

先得到默认网关的mac

2  向服务器 3 次握手

3 以tcp的方式发送http协议的请求数据 给 服务器
4 服务器tcp的方式回应http协议的应答数据 给浏览器

为什么用mac   可以查查







### 4 Python高级

#### GIL锁

GIL（全局解释区锁）面试题如下

> 描述Python GIL的概念， 以及它对python多线程的影响？编写一个多线程抓取网页的程序，并阐明多线程抓取程序是否可比单线程性能有提升，并解释原因。

Guido的声明：http://www.artima.com/forums/flat.jsp?forum=106&thread=214235

> 参考答案:
>
> 1. Python语言和GIL没有半毛钱关系。仅仅是由于历史原因在Cpython虚拟机(解释器)，难以移除GIL。
> 2. GIL：全局解释器锁。每个线程在执行的过程都需要先获取GIL，保证同一时刻只有一个线程可以执行代码。
> 3. 线程释放GIL锁的情况： 在IO操作等可能会引起阻塞的system call之前,可以暂时释放GIL,但在执行完毕后,必须重新获取GIL Python 3.x使用计时器（执行时间达到阈值后，当前线程释放GIL）或Python 2.x，tickets计数达到100
> 4. Python使用多进程是可以利用多核的CPU资源的。
> 5. 多线程爬取比单线程性能有提升，因为遇到IO阻塞会自动释放GIL锁

**pass 占位符，空语句**

Python 的多线程由于存在著名的 GIL，无法让两个线程真正“同时运行”，所以实际上是无法到达并行状态的 

**GIL 使多线程程序在同一时刻只有一个线程在运行**，只会使用一个核，GIL 是cpython解释器存在的问题

*一般多进程比多线程消耗资源，但如果使用cpython解释器，可以用多进程代替多线程*

>python由于历史遗留的问题，严格说多个线程并不会同时执行（没法有效利用多核处理器，python的并发只是一个核心的交替执行不同的代码）。
>
>解释器执行代码时，有一个GIL锁：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。
>
>这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。

计算密集型 不用线程，使用进程，而 IO密集型 可以 使用 线程，也可以使用协程

如何解决 GIL：1. 换解释器 2. 换语言，用其他语言替代线程做的事(python语言可以对c程序代码进行调用，还有java\c++\js)

> [Python3调用C程序示例](https://www.jianshu.com/p/edb8698d1374)

#### 深拷贝、浅拷贝

直接赋值：其实就是对象的引用（别名） 

浅拷贝：浅拷贝是对于一个对象的顶层拷贝，通俗的理解是：拷贝了引用，并没有拷贝内容

深拷贝：深拷贝是对于一个对象所有层次的拷贝(递归)

```python
import copy
a1 = [11, 22]
b1 = a1  # 直接赋值：指向/就是对象的引用
print(a1, b1)
print(id(a1), id(b1))  # id() 指向数据的地址
a1.append(33)
print(a1, b1)
print("-" * 20)
a2 = [11, 22]
b2 = copy.deepcopy(a2)  # 对a指向的列表进行深拷贝
print(a2, b2)
print(id(a2), id(b2))
a2.append(33)
print(a2, b2)
print("-" * 20)
# copy.copy 浅拷贝 是对于一个对象的顶层拷贝  
# c 和 d 是一个独立的对象，但他们的子对象还是指向统一对象（是引用）
# copy.deepcopy(), c 和 e 完全拷贝了父对象及其子对象，两者是完全独立的。
a, b = [11, 22], [44, 55]
c = [a, b]
d = copy.copy(c)
e = copy.deepcopy(c)
print(id(c), id(d), id(e))
print(id(c[0]), id(d[0]), id(e[0]))
a.append(33)
c.append(66)
print(c, d, e)
# 1921547446856 1921547446152 1921547446792
# 1921547446984 1921547446984 1921547446920
# [[11, 22, 33], [44, 55], 66] [[11, 22, 33], [44, 55]] [[11, 22], [44, 55]]
'''浅拷贝对不可变类型和可变类型的copy不同
copy.copy对于可变类型，会进行浅拷贝
copy.copy对于不可变类型(不会修改，所以无需拷贝)，不会拷贝，仅仅是指向()'''
a3 = (11, 22)
b3 = a3
print(id(a3), id(b3))
# 元组中为不可变类型(全为不可变类型数据)，copy 和 deepcopy 都不会拷贝，仅仅是指向
# 元组中为 可变类型(存在可变类型数据，即使最顶层为不可变)，copy 不会拷贝，但deepcopy会 深拷贝
列表的切片 复制列表-list[:]  为 浅拷贝
字典的copy()方法 为 浅拷贝
字典的value 不存于字典，只存引用
函数传递的是引用，函数中的操作会修改源列表
```

首先**深拷贝和浅拷贝**都是对象的拷贝，都会生成一个看起来相同的对象，他们本质的区别是拷贝出来的对象的地址是否和原对象一样，也就是**地址的复制还是值的复制**的区别。

#####  什么是可变对象，什么是不可变对象：

- 可变对象是指，一个对象在不改变其所指向的地址的前提下，可以修改其所指向的地址中的值；
- 不可变对象是指，一个对象所指向的地址上值是不能修改的，如果你修改了这个对象的值，那么它指向的地址就改变了，相当于你把这个对象指向的值复制出来一份，然后做了修改后存到另一个地址上了，但是可变对象就不会做这样的动作，而是直接在对象所指的地址上把值给改变了，而这个对象依然指向这个地址。

列表中为字符串对象时，深拷贝后虽然列表中元素的地址一样，但是列表的地址不同。

#### 私有化

- `xx`: 公有变量
- `_x`: 单前置下划线,私有化属性或方法，from module import *禁止导入,类对象和子类可以访问
- `__xx`：双前置下划线,避免与子类中的属性命名冲突，无法在外部直接访问(名字重整所以访问不到) 
- `__xx__`：双前后下划线,用户名字空间的魔法对象或属性。例如:`__init__` , __ 不要自己发明这样的名字
- `xx_`：单后置下划线,用于避免与Python关键词的冲突，不建议用

`__xx`：私有属性/方法，不会继承，`__xx__`：公有属性/方法，会继承

通过name mangling（名字重整(目的就是以防子类意外重写基类的方法或者属性)如：_Class__object）机制就可以访问private了。

> 在一个类中定义的属性（无论是类属性还是实例属性），如果是以 双下划线 (`__`) 开头，那么这个属性是对外 (包括其子类中) 不可见的，类似于 java 中的 private 属性。如何做到这一点呢, 毕竟 Python 并没有真正意义上的访问约束机制（比如 private, protected 修饰符）。Python 的做法是 name mangling(名字重整)。具体做法是 如果你在某个类 clsA 中定义了一个属性，名称是  `__a`, 那么 python 会把这个属性更名成  `_clsA__a`， 但是更名后不影响你在内部使用，你在类的内部，还是可以使用`self.__a` 来范围。如果你非要在外部访问 这个属性，就只能使用 inst._clsA__a 来访问。 

```python
class Person(object):
    def __init__(self, name, age, taste):
        self.name = name
        self._age = age  # 禁止导入
        self.__taste = taste  # 私有属性
    def showperson(self):
        print(self.name, self._age, self.__taste)  # 通过方法可以访问私有属性
    def dowork(self):
        self._work()
        self.__away()
    def _work(self):  # 禁止导入
        print('my _work')
    def __away(self):    # 私有方法
        print('my __away')
class Student(Person):
    def construction(self, name, age, taste):
        self.name = name
        self._age = age  # 禁止导入
        self.__taste = taste  # 私有属性
    def showstudent(self):
        print(self.name, self._age, self.__taste)
    @staticmethod
    def testbug():
        _Bug.showbug()  # 静态方法，通过类直接调用，不需要创建对象，不会隐式传递self
# 模块内可以访问，当from  cur_module import *时，不导入
class _Bug(object):  # 禁止导入
    @staticmethod
    def showbug():
        print("showbug")
s1 = Student('jack', 25, 'football')
s1.showperson()
print('*'*20)
# 无法访问__taste,导致报错
# s1.showstudent() # 这成了子类对象访问私有属性
s1.construction('rose', 30, 'basketball')
s1.showperson()  # 私有属性没法改
print('*'*20)
s1.showstudent()
print('*'*20)
Student.testbug()
```

小结：

- 父类中属性名为`__名字`的，子类不继承，子类不能访问
- 如果在子类中向`__名字`赋值，那么会在子类中定义的一个与父类相同名字的属性
- `_名`的变量、函数、类在使用`from xxx import *`时都不会被导入

#### import导入模块

如果模块是被**第一次**导入, 它将被加载并执行。 一个模块只被加载一次, 无论它被导入多少次。 这可以阻止多重导入时代码被多次执行。  

##### 搜索路径：

导入 sys 模块，打印 `sys.path` 输出 列表

- 从上面列出的目录里依次查找要导入的模块文件
- `''`表示当前路径
- 列表中的路径的先后顺序代表了python解释器在搜索模块时的先后顺序

##### 程序执行时添加新的模块路径：

```python
sys.path.append('/home/itcast/xxx')
sys.path.insert(0, '/home/itcast/xxx')  # 可以确保先搜索这个路径
```

##### 重新导入模块

模块被导入后进行过修改，`import module`不能重新导入模块，重新导入需用`reload`

(在交互模式下 导入，不结束，新开终端，修改模块内容，源导入不会更新；先导入的已经加载内存，修改的是硬盘)

```python
from imp import reload
reload(module_name)
```

##### Import 和from是赋值语句

像def一样，import和from是可执行的语句，他们可以出现在if中，可以出现在函数中，执行到这些语句的时候才会进行解析，也就是说，被导入的模块和变量名只有在对应的import或from语句执行后才可以使用。

**Import将整个模块对象赋值给一个变量名**。（import xxx  两个过程：将xxx.py导入到python解释器；定义xxx变量，指向模块）

**From将一个或多个变量名赋值给另外一个模块中同名的对象**。所以from容易污染命名空间。

##### 不建议用 `from module import *`

 在实践中, `from module import *` 不是良好的编程风格，如果使用from导入变量，且那些变量碰巧和作用域中现有变量同名，那么变量名就会被悄悄覆盖掉。使用import语句的时候就不会发生这种问题，因为我们是通过模块名才获取的变量名，像module.attr不会和现有作用域的attr冲突。 

###### 何时使用：

只在两种场合下建议使用这样的方法, 一个场合是：目标模块中的属性非常多, 反复键入模块名很不方便 , 例如 Tkinter (Python/Tk) 和 NumPy (Numeric Python) 模块 , 可能还有 socket 模块。

另一个场合是在交互解释器下, 因为这样可以减少输入次数。

##### 多模块开发时的注意点

```python
# common.py  公用模块
RECV_DATA_LIST = list()  # 用来存储数据
HANDLE_FLAG = False  # 用来标记是否处理完成
# handle_msg.py  只负责处理
from common import RECV_DATA_LIST
# from common import HANDLE_FLAG
import common
def handle_data():
    """模拟处理recv_msg模块接收的数据"""
    print("--->handle_data")
    for i in RECV_DATA_LIST:
        print(i)
    # 既然处理完成了，那么将变量HANDLE_FLAG设置为True，意味着处理完成
    # global HANDLE_FLAG
    # HANDLE_FLAG = True
    common.HANDLE_FLAG = True
def test_handle_data():
    """测试处理是否完成，变量是否设置为True"""
    print("--->test_handle_data")
    # if HANDLE_FLAG:
    if common.HANDLE_FLAG:
        print("=====已经处理完成====")
    else:
        print("=====未处理完成====")
# recv_msg.py  只负责收
from common import RECV_DATA_LIST
# from common import HANDLE_FLAG
import common
def recv_msg():
    """模拟接收到数据，然后添加到common模块中的列表中"""
    print("--->recv_msg")
    for i in range(5):
        RECV_DATA_LIST.append(i)
def test_recv_data():
    """测试接收到的数据"""
    print("--->test_recv_data")
    print(RECV_DATA_LIST)
def recv_msg_next():
    """已经处理完成后，再接收另外的其他数据"""
    print("--->recv_msg_next")
    # if HANDLE_FLAG:
    if common.HANDLE_FLAG:
        print("------发现之前的数据已经处理完成，这里进行接收其他的数据(模拟过程...)----")
    else:
        print("------发现之前的数据未处理完，等待中....------")
# main.py
from recv_msg import *
from handle_msg import *
def main():
    recv_msg()  # 1. 接收数据
    test_recv_data()  # 2. 测试是否接收完毕
    recv_msg_next()  # 3. 判断如果处理完成，则接收其它数据
    handle_data()  # 4. 处理数据
    test_handle_data()  # 5. 测试是否处理完毕
    recv_msg_next()  # 6. 判断如果处理完成，则接收其它数据
if __name__ == "__main__":
    main()
```

存在的可能出错的点：

`HANDLE_FLAG` 通过 先导入common模块，再通过`common.HANDLE_FLAG` 方式读取/修改值时，由于两个文件中对应语句都指向了 common中的`HANDLE_FLAG`（因为两个变量common都指向了common.py模块） ，因此读取/修改时一致，如下图。

<img width="964" alt="QQ20171024-081134@2x" src="https://user-images.githubusercontent.com/51505633/79428333-982e2780-7ff8-11ea-9cdf-3a66cd736e90.png" style="zoom:50%;" >

而通过 `from common import HANDLE_FLAG`导入时，定义变量`HANDLE_FLAG` ，其指向 common中`HANDLE_FLAG` 的值(False)。`handle_msg` 中修改值时，`HANDLE_FLAG`变量会指向新的地址，而不是修改源地址中的值。（RECV_DATA_LIST 为list，通过append方法，会修改地址中的值；但如果用 = 新列表方式修改，也不会修改值，而是指向新列表）这样导致recv_msg读取时读到错误值，产生 bug。

导入模块语句也相当于赋值，所以为全局变量，需要 global 声明，如果没有，`HANDLE_FLAG` 变量指向了值为 `True`的新地址，且为局部变量，不会影响同文件的test_handle_data函数。

使用global 声明后，虽然成为了全局变量，会影响同文件的test_handle_data函数，但是模块中的`HANDLE_FLAG` 会指向新的地址，recv_msg_next函数中读取的还是源地址的值。

<img width="950" alt="QQ20171024-080610@2x" src="https://user-images.githubusercontent.com/51505633/79428043-2ce45580-7ff8-11ea-8edc-d7b37428ca33.png" style="zoom:50%;" >

#### 再议 封装、继承、多态

封装，对象的属性是独有的，但是方法是公有的，创建对象时独有变量，而通过模板的引用来调用函数(`__class__`方法)

`__dict__`方法标记对象的属性

self 是形参，可以为其他，对应就行

##### 封装好处

> 1. 在使用面向过程编程时，当需要对数据处理时，需要考虑用哪个模板中哪个函数来进行操作，但是当用面向对象编程时，因为已经将数据存储到了这个独立的空间中，这个独立的空间（即对象）中通过一个特殊的变量（__class__）能够获取到类（模板），而且这个类中的方法是有一定数量的，与此类无关的将不会出现在本类中，因此需要对数据处理时，可以很快速的定位到需要的方法是谁 这样更方便
> 2. 全局变量是只能有1份的，多很多个函数需要多个备份时，往往需要利用其它的变量来进行储存；而通过封装 会将用来存储数据的这个变量 变为了对象中的一个“全局”变量，只要对象不一样那么这个变量就可以再有1份，所以这样更方便
> 3. 代码划分更清晰

##### 继承好处

> 1. 能够提升代码的重用率，即开发一个类，可以在多个子功能中直接使用
> 2. 继承能够有效的进行代码的管理，当某个类有问题只要修改这个类就行，而其继承这个类的子类往往不需要就修改

多态：多种形态。

子类重写方法，调用子类的；没重写，调用父类的，但调用的是同一个方法(名)  -- **只需写成父类方法的调用方式**。

```python
class MiniOS(object):
    """MiniOS 操作系统类 """
    def __init__(self, name):
        self.name = name
        self.apps = []  # 安装的应用程序名称列表

    def __str__(self):  # 返回对象的描述信息（必须为字符串），print 函数打印对象时自定义输出使用
        return "%s 安装的软件列表为 %s" % (self.name, str(self.apps))

    def install_app(self, app):
        # 判断是否已经安装了软件
        if app.name in self.apps:
            print("已经安装了 %s，无需再次安装" % app.name)
        else:
            app.install()  '''这实现多态!'''
            self.apps.append(app.name)
class App(object):
    def __init__(self, name, version, desc):
        self.name = name
        self.version = version
        self.desc = desc
    def __str__(self):
        return "%s 的当前版本是 %s - %s" % (self.name, self.version, self.desc)
    def install(self):
        print("将 %s [%s] 的执行程序复制到程序目录..." % (self.name, self.version))
class PyCharm(App):
    pass
class Chrome(App):
    def install(self):
        print("正在解压缩安装程序...")
        super().install()
linux = MiniOS("Linux")
print(linux)
pycharm = PyCharm("PyCharm", "1.0", "python 开发的 IDE 环境")
chrome = Chrome("Chrome", "2.0", "谷歌浏览器")
linux.install_app(pycharm)
linux.install_app(chrome)
linux.install_app(chrome)
print(linux)
```

#### 多继承以及MRO顺序

**函数名就是一个变量，指向一个函数**

**重写：**重新覆盖，子类覆盖父类中的同名方法，会调用子类的方法

**重载：**方法名相同，根据形参的数量，类型，自动调用不同方法（**Python 中几乎没有**，同名的方法/函数，后一个会覆盖前一个。(python中 `+` 是重载 数值和字符串两个情况时结果不一致)）

##### 调用被重写的父类方法的方式   

 重写之后，如果发现仍需要父类方法，有以下三种方式：

1. 父类名.父类方法() 

   使用类名调用父类被重写的方法时， 需要显式绑定第一个参数self ，eg：`Animal.__init__(self)`

   > python3基本上要把这种方式淘汰了。
   >
   > 它的机制你可以理解为：如果“孙子”类有俩“爸爸”类，他的两个“爸爸”类在自己的某一个方法中都调用了“爷爷”类的那个方法，当调用两个“爸爸”类中的这个方法时，而于是就造成了爷爷的代码被调用了多次（菱形继承）。一方面太冗余，另一方面可能出现不必要的bug，而如果使用的是super()方式的话，会按照类的`__mro__`属性的顺序来调用，就不存在这方面的问题。所以 父类名.父类方法() 的方式不推荐使用。

   示例：

   ```python
   # 单独调用父类的方法
   print("******多继承使用类名.__init__ 发生的状态******")
   class Parent(object):
       def __init__(self, name):
           print('parent的init开始被调用')
           self.name = name
           print('parent的init结束被调用')
   class Son1(Parent):
       def __init__(self, name, age):
           print('Son1的init开始被调用')
           self.age = age
           Parent.__init__(self, name)
           print('Son1的init结束被调用')
   class Son2(Parent):
       def __init__(self, name, gender):
           print('Son2的init开始被调用')
           self.gender = gender
           Parent.__init__(self, name)
           print('Son2的init结束被调用')
   class Grandson(Son1, Son2):
       def __init__(self, name, age, gender):
           print('Grandson的init开始被调用')
           Son1.__init__(self, name, age)  # 单独调用父类的初始化方法
           Son2.__init__(self, name, gender)
           print('Grandson的init结束被调用')
   gs = Grandson('grandson', 12, '男')
   print('姓名：', gs.name)
   print('年龄：', gs.age)
   print('性别：', gs.gender)
   print("******多继承使用类名.__init__ 发生的状态******\n\n")
   ```

2. super().父类方法()

   ```python
   # 多继承中super调用所有父类的被重写的方法
   print("******多继承使用super().__init__ 发生的状态******")
   class Parent(object):
       def __init__(self, name, *args, **kwargs):  # 为避免多继承报错，使用不定长参数，接受参数
           print('parent的init开始被调用')
           self.name = name
           print('parent的init结束被调用')
   class Son1(Parent):
       def __init__(self, name, age, *args, **kwargs):  # 为避免多继承报错，使用不定长参数，接受参数
           print('Son1的init开始被调用')
           self.age = age
           super().__init__(name, *args, **kwargs)  # 为避免多继承报错，使用不定长参数，接受参数
           # 这传递的是 调用函数时的数据  见下方拆包
           print('Son1的init结束被调用')
   class Son2(Parent):
       def __init__(self, name, gender, *args, **kwargs):  # 为避免多继承报错，使用不定长参数，接受参数
           print('Son2的init开始被调用')
           self.gender = gender
           super().__init__(name, *args, **kwargs)  # 为避免多继承报错，使用不定长参数，接受参数
           print('Son2的init结束被调用')
   class Grandson(Son1, Son2):
       def __init__(self, name, age, gender):
           print('Grandson的init开始被调用')
           # 多继承时，相对于使用类名.__init__方法，要把每个父类全部写一遍
           # 而super只用一句话，执行了全部父类的方法，这也是为何多继承需要全部传参的一个原因
           # super(Grandson, self).__init__(name, age, gender) 
           # 子类名可以修改，修改后按__mro__中对应类名的下个类中的对应方法
           super().__init__(name, age, gender)  # 默认是自己的类类名，等同于上一句
           # super()默认拿着自己的类名到MRO输出中找，找到匹配项的下一个的__init__执行
           print('Grandson的init结束被调用')
   print(Grandson.__mro__)
   # (<class '__main__.Grandson'>, <class '__main__.Son1'>, <class '__main__.Son2'>, <class '__main__.Parent'>, <class 'object'>)
   gs = Grandson('grandson', 12, '男')
   print('姓名：', gs.name)
   print('年龄：', gs.age)
   print('性别：', gs.gender)
print("******多继承使用super().__init__ 发生的状态******\n\n")
   ```

   `类名.__mro__`是依照C3算法衍生出来的一个类的属性，该属性的特点是：
   
1. 使**所有继承的类只执行一次**。
   2. 返回一个元祖，元祖中是**使用super()方法时调用父类方法的顺序**。（顺序是：拿着类名去元祖里面找，找到了之后，便去执行**它的‘下一个’对应的类中对应的方法**）
   
   > 注意：以上2个代码执行的结果不同。
   > 如果2个子类中都继承了父类，当在子类中**通过父类名调用**时，parent被执行了**2次**
   > 如果2个子类中都继承了父类，当在子类中**通过super调用**时，parent被执行了**1次**


3. super(子类名, self).父类方法()

    eg：`super(Son1, self).__init__()`，根据 `类名.__mro__` 的输出，会执行 Son2 中的`__init__()`
    
    **为什么要有self这个参数？**供参考：将自己作为实参传递给这个继承的类中，才能执行对应方法的代码
    
    使用 super() 时，为避免多继承报错，使用不定长参数，接受参数

##### 拆包

`*args `用来将参数打包成tuple给函数体调用； `**kwargs `打包关键字参数成dict给函数体调用 

```python
def test1(a, b, *args, **kwargs):  # args 接收(33,44,55)，不是*args接收的   变量名没有*!
    print(a, ">>", b, ">>", args, ">>", kwargs)
    # *就是拆包指令，所以输出args时是以未拆包，也就是原元组进行print的
    print("*args <<< ", *args)
    test2(a, b, args, kwargs)  # 相当于 test2(11,22,(33,44,55),{'age':18,'name':'douzi'})
    test2(a, b, *args, kwargs)  # 相当于 test2(11,22,33,44,55,{'age':18,'name':'douzi'})
    test2(a, b, *args, **kwargs)  # 相当于 test2(11,22,33,44,55, name="douzi", age=18)
def test2(a, b, *args, **kwargs):
    print("-2- ", a, ">>", b, ">>", args, ">>", kwargs)
test1(11, 22, 33, 44, 55, name="douzi", age=18)
```

 `*` 在Python中就一个作用，就是“拆包”， 拆包”顾名思义就是打开包，将包(在此指元组Tuple、字典Dictionary)里面的数据拆分成一个个单独的数据。 

##### 单继承中super

```python
print("******单继承使用super().__init__ 发生的状态******")
class Parent(object):
    def __init__(self, name):
        print('parent的init开始被调用')
        self.name = name
        print('parent的init结束被调用')
class Son1(Parent):
    def __init__(self, name, age):
        print('Son1的init开始被调用')
        self.age = age
        super().__init__(name)  # 单继承不能提供全部参数
        print('Son1的init结束被调用')
class Grandson(Son1):
    def __init__(self, name, age, gender):
        print('Grandson的init开始被调用')
        super().__init__(name, age)  # 单继承不能提供全部参数
        print('Grandson的init结束被调用')
gs = Grandson('grandson', 12, '男')
print('姓名：', gs.name)
print('年龄：', gs.age)
#print('性别：', gs.gender)
print("******单继承使用super().__init__ 发生的状态******\n\n")
```

总结：

1. `super().__init__`相对于`类名.__init__`，在单继承上用法基本无差
2. 但在多继承上有区别，super方法能保证每个父类的方法只会执行一次，而使用类名的方法会导致方法被执行多次，具体看前面的输出结果
3. 多继承时，使用super方法，对父类的传参数，应该是由于python中super的算法导致的原因，必须把参数全部传递，否则会报错
4. 单继承时，使用super方法，则不能全部传递，只能传父类方法所需的参数，否则会报错
5. 多继承时，相对于使用`类名.__init__`方法，要把每个父类全部写一遍, 而使用super方法，只需写一句话便执行了全部父类的方法，这也是为何多继承需要全部传参的一个原因

##### 面试题

> 以下的代码的输出将是什么? 说出你的答案并解释。

```python
class Parent(object):
    x = 1
class Child1(Parent):
    pass
class Child2(Parent):
    pass
print(Parent.x, Child1.x, Child2.x)  # 1 1 1
Child1.x = 2  # 添加类属性
print(Parent.x, Child1.x, Child2.x)  # 1 2 1
Parent.x = 3  # 修改父类属性
print(Parent.x, Child1.x, Child2.x)  # 3 2 3
```

这个答案的关键是，在 Python 中，**类变量在内部是作为字典处理的**。如果一个变量的名字没有在当前类的字典中发现，将搜索祖先类（比如父类）直到被引用的变量名被找到（如果这个被引用的变量名既没有在自己所在的类又没有在祖先类中找到，会引发一个 AttributeError 异常 ）。**（也是按MRO顺序查找）**

因此，在父类中设置 x = 1 会使得类变量 x 在引用该类和其任何子类中的值为 1。因此第一个的输出是` 1 1 1`。

随后，如果任何它的子类重写了该值(如执行语句 Child1.x = 2)，该值仅仅在子类中被改变。因此第二个的输出是` 1 2 1`。

最后，如果该值在父类中被改变(如执行 Parent.x = 3)，这个改变会影响到任何未重写该值的子类当中的值（在这个示例中被影响的子类是 Child2）。这就是为什么第三个 print 输出是` 3 2 3`。

> 如果一个类继承了某个类，可以理解为在子类中有个属性指向了继承的父类，而不是复制了父类的东西

#### 静态方法和类方法





return 类名（）   代表什么   返回一个实例对象？

















# TODO:

服务器那 后几个复现     2 的问题解决

file 部分 博客  看 wb  rb

写实拷贝  创建子进程时 会发生什么





















- 所谓`进程`指的是：运行的程序以及运行时用到的资源这个整体称之为进程（在讲解多任务编程时进行详细讲解）
- 所谓`进程间通信`指的是：运行的程序之间的数据共享